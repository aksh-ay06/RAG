{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5224a08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WEEK 2 CONTAINER & SERVICE HEALTH CHECK\n",
      "==================================================\n",
      "Project root: /media/akshay/DATA/Portfolio/RAG\n",
      "\n",
      "1. Checking container status...\n",
      "✓ Containers are running:\n",
      "   NAME             IMAGE                                            COMMAND                  SERVICE                 CREATED         STATUS                   PORTS\n",
      "   rag-airflow      rag-airflow                                      \"/entrypoint.sh\"         airflow                 4 minutes ago   Up 4 minutes (healthy)   0.0.0.0:8080->8080/tcp, [::]:8080->8080/tcp\n",
      "   rag-api          rag-api                                          \"uvicorn src.main:ap…\"   api                     4 minutes ago   Up 4 minutes (healthy)   0.0.0.0:8000->8000/tcp, [::]:8000->8000/tcp\n",
      "   rag-dashboards   opensearchproject/opensearch-dashboards:2.19.0   \"./opensearch-dashbo…\"   opensearch-dashboards   4 minutes ago   Up 4 minutes (healthy)   0.0.0.0:5601->5601/tcp, [::]:5601->5601/tcp\n",
      "   rag-ollama       ollama/ollama:0.11.2                             \"/bin/ollama serve\"      ollama                  4 minutes ago   Up 4 minutes (healthy)   0.0.0.0:11434->11434/tcp, [::]:11434->11434/tcp\n",
      "   rag-opensearch   opensearchproject/opensearch:2.19.0              \"./opensearch-docker…\"   opensearch              4 minutes ago   Up 4 minutes (healthy)   0.0.0.0:9200->9200/tcp, [::]:9200->9200/tcp, 9300/tcp, 0.0.0.0:9600->9600/tcp, [::]:9600->9600/tcp, 9650/tcp\n",
      "   rag-postgres     postgres:16-alpine                               \"docker-entrypoint.s…\"   postgres                4 minutes ago   Up 4 minutes (healthy)   0.0.0.0:5432->5432/tcp, [::]:5432->5432/tcp\n",
      "\n",
      "2. Checking service health...\n",
      "✓ FastAPI: Healthy\n",
      "✓ PostgreSQL (via API): Healthy\n",
      "✓ Ollama: Healthy\n",
      "✓ OpenSearch: Healthy\n",
      "✓ Airflow: Healthy\n",
      "\n",
      "==================================================\n",
      "✓ ALL SERVICES HEALTHY! Ready for Week 2 development.\n"
     ]
    }
   ],
   "source": [
    "# Check if Fresh Containers are Built and All Services Healthy\n",
    "import subprocess\n",
    "import requests\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"WEEK 2 CONTAINER & SERVICE HEALTH CHECK\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Find project root\n",
    "current_dir = Path.cwd()\n",
    "if current_dir.name == \"module2\" and current_dir.parent.name == \"notebooks\":\n",
    "    project_root = current_dir.parent.parent\n",
    "elif (current_dir / \"compose.yml\").exists():\n",
    "    project_root = current_dir\n",
    "else:\n",
    "    print(\"✗ Could not find project root\")\n",
    "    exit()\n",
    "\n",
    "print(f\"Project root: {project_root}\")\n",
    "\n",
    "# Step 1: Check if containers are built and running\n",
    "print(\"\\n1. Checking container status...\")\n",
    "try:\n",
    "    result = subprocess.run(\n",
    "        [\"docker\", \"compose\", \"ps\", \"--format\", \"table\"],\n",
    "        cwd=str(project_root),\n",
    "        capture_output=True,\n",
    "        text=True,\n",
    "        timeout=10\n",
    "    )\n",
    "    \n",
    "    if result.returncode == 0 and result.stdout.strip():\n",
    "        print(\"✓ Containers are running:\")\n",
    "        for line in result.stdout.strip().split('\\n'):\n",
    "            print(f\"   {line}\")\n",
    "    else:\n",
    "        print(\"✗ No containers running or docker compose failed\")\n",
    "        print(\"Please run the build commands from the markdown cell above\")\n",
    "        exit()\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"✗ Error checking containers: {e}\")\n",
    "    print(\"Please run the build commands from the markdown cell above\")\n",
    "    exit()\n",
    "\n",
    "# Step 2: Check all service health (corrected endpoints)\n",
    "print(\"\\n2. Checking service health...\")\n",
    "services_to_test = {\n",
    "    \"FastAPI\": \"http://localhost:8000/api/v1/health\",\n",
    "    \"PostgreSQL (via API)\": \"http://localhost:8000/api/v1/health\", \n",
    "    \"Ollama\": \"http://localhost:11434/api/version\",\n",
    "    \"OpenSearch\": \"http://localhost:9200/_cluster/health\",\n",
    "    \"Airflow\": \"http://localhost:8080/health\"\n",
    "}\n",
    "\n",
    "all_healthy = True\n",
    "for service_name, url in services_to_test.items():\n",
    "    try:\n",
    "        response = requests.get(url, timeout=5)\n",
    "        if response.status_code == 200:\n",
    "            print(f\"✓ {service_name}: Healthy\")\n",
    "        else:\n",
    "            print(f\"✗ {service_name}: HTTP {response.status_code}\")\n",
    "            all_healthy = False\n",
    "    except requests.exceptions.ConnectionError:\n",
    "        print(f\"✗ {service_name}: Not accessible\")\n",
    "        all_healthy = False\n",
    "    except Exception as e:\n",
    "        print(f\"✗ {service_name}: {type(e).__name__}\")\n",
    "        all_healthy = False\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "if all_healthy:\n",
    "    print(\"✓ ALL SERVICES HEALTHY! Ready for Week 2 development.\")\n",
    "else:\n",
    "    print(\"✗ Some services need attention.\")\n",
    "    print(\"If you just rebuilt containers, wait 1-2 minutes and run this cell again.\")\n",
    "    print(\"Airflow and OpenSearch take longest to start up.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1e055ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python Version: 3.12.3\n",
      "Environment: /media/akshay/DATA/Portfolio/RAG/.venv/bin/python3\n",
      "✓ Project root: /media/akshay/DATA/Portfolio/RAG\n"
     ]
    }
   ],
   "source": [
    "# Environment Check\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "print(f\"Python Version: {sys.version_info.major}.{sys.version_info.minor}.{sys.version_info.micro}\")\n",
    "print(f\"Environment: {sys.executable}\")\n",
    "\n",
    "# Find project root\n",
    "current_dir = Path.cwd()\n",
    "if current_dir.name == \"module2\" and current_dir.parent.name == \"notebooks\":\n",
    "    project_root = current_dir.parent.parent\n",
    "elif (current_dir / \"compose.yml\").exists():\n",
    "    project_root = current_dir\n",
    "else:\n",
    "    project_root = None\n",
    "\n",
    "if project_root and (project_root / \"compose.yml\").exists():\n",
    "    print(f\"✓ Project root: {project_root}\")\n",
    "    # Add project to Python path\n",
    "    sys.path.insert(0, str(project_root))\n",
    "else:\n",
    "    print(\"✗ Missing compose.yml - check directory\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc49b21b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WEEK 2 PREREQUISITE CHECK\n",
      "==================================================\n",
      "✓ FastAPI: Healthy\n",
      "✓ PostgreSQL (via API): Healthy\n",
      "✓ Ollama: Healthy\n",
      "✓ OpenSearch: Healthy\n",
      "✓ Airflow: Healthy\n",
      "\n",
      "All services healthy! Ready for Week 2 development.\n"
     ]
    }
   ],
   "source": [
    "# Test Service Connectivity\n",
    "import requests\n",
    "import subprocess\n",
    "import json\n",
    "\n",
    "services_to_test = {\n",
    "    \"FastAPI\": \"http://localhost:8000/api/v1/health\",\n",
    "    \"PostgreSQL (via API)\": \"http://localhost:8000/api/v1/health\", \n",
    "    \"Ollama\": \"http://localhost:11434/api/version\",\n",
    "    \"OpenSearch\": \"http://localhost:9200/_cluster/health\",\n",
    "    \"Airflow\": \"http://localhost:8080/health\"  \n",
    "}\n",
    "\n",
    "print(\"WEEK 2 PREREQUISITE CHECK\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "all_healthy = True\n",
    "\n",
    "for service_name, url in services_to_test.items():\n",
    "    try:\n",
    "        response = requests.get(url, timeout=5)\n",
    "        if response.status_code == 200:\n",
    "            print(f\"✓ {service_name}: Healthy\")\n",
    "        else:\n",
    "            print(f\"✗ {service_name}: HTTP {response.status_code}\")\n",
    "            all_healthy = False\n",
    "    except requests.exceptions.ConnectionError:\n",
    "        print(f\"✗ {service_name}: Not accessible\")\n",
    "        all_healthy = False\n",
    "    except Exception as e:\n",
    "        print(f\"✗ {service_name}: {type(e).__name__}\")\n",
    "        all_healthy = False\n",
    "\n",
    "print()\n",
    "if all_healthy:\n",
    "    print(\"All services healthy! Ready for Week 2 development.\")\n",
    "else:\n",
    "    print(\"Some services need attention. Check Week 1 notebook.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c54d76c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TESTING ARXIV API CLIENT\n",
      "========================================\n",
      "✓ Client created: https://export.arxiv.org/api/query\n",
      "   Rate limit: 3.0s\n",
      "   Max results: 100\n",
      "   Category: cs.AI\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test arXiv API Client\n",
    "import asyncio\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Import our arXiv client\n",
    "from src.services.arxiv.factory import make_arxiv_client\n",
    "\n",
    "print(\"TESTING ARXIV API CLIENT\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Create client\n",
    "arxiv_client = make_arxiv_client()\n",
    "print(f\"✓ Client created: {arxiv_client.base_url}\")\n",
    "print(f\"   Rate limit: {arxiv_client.rate_limit_delay}s\")\n",
    "print(f\"   Max results: {arxiv_client.max_results}\")\n",
    "print(f\"   Category: {arxiv_client.search_category}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b26b37d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 1: Fetch Recent CS.AI Papers\n",
      "✓ Fetched 2 papers\n",
      "   1. [2602.06043v1] Shared LoRA Subspaces for almost Strict Continual Learning...\n",
      "      Authors: Prakhar Kaushik, Ankit Vaidya...\n",
      "      Categories: cs.LG, cs.AI, cs.CV\n",
      "      Published: 2026-02-05T18:59:58Z\n",
      "\n",
      "   2. [2602.06039v1] DyTopo: Dynamic Topology Routing for Multi-Agent Reasoning v...\n",
      "      Authors: Yuxing Lu, Yucheng Hu...\n",
      "      Categories: cs.AI\n",
      "      Published: 2026-02-05T18:59:51Z\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test Paper Fetching\n",
    "async def test_paper_fetching():\n",
    "    \"\"\"Test fetching papers from arXiv with rate limiting.\"\"\"\n",
    "    \n",
    "    print(\"Test 1: Fetch Recent CS.AI Papers\")\n",
    "    try:\n",
    "        papers = await arxiv_client.fetch_papers(\n",
    "            max_results=2, \n",
    "            sort_by=\"submittedDate\",\n",
    "            sort_order=\"descending\"\n",
    "        )\n",
    "        \n",
    "        print(f\"✓ Fetched {len(papers)} papers\")\n",
    "        \n",
    "        if papers:\n",
    "            for i, paper in enumerate(papers[:2], 1):\n",
    "                print(f\"   {i}. [{paper.arxiv_id}] {paper.title[:60]}...\")\n",
    "                print(f\"      Authors: {', '.join(paper.authors[:2])}{'...' if len(paper.authors) > 2 else ''}\")\n",
    "                print(f\"      Categories: {', '.join(paper.categories)}\")\n",
    "                print(f\"      Published: {paper.published_date}\")\n",
    "                print()\n",
    "        \n",
    "        return papers\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error fetching papers: {e}\")\n",
    "        if \"503\" in str(e):\n",
    "            print(\"   arXiv API temporarily unavailable (normal)\")\n",
    "            print(\"   Rate limiting and error handling working correctly\")\n",
    "        return []\n",
    "\n",
    "# Run the test\n",
    "papers = await test_paper_fetching()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3bccc1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 2: Date Range Filtering\n",
      "✓ Date filtering test: 5 papers from 20250808-20250809\n",
      "   1. [2508.07111v1] Investigating Intersectional Bias in Large Language Models u...\n",
      "      Authors: Falaah Arif Khan, Nivedha Sivakumar...\n",
      "      Categories: cs.CL, cs.AI\n",
      "      Published: 2025-08-09T22:24:40Z\n",
      "\n",
      "   2. [2508.07107v2] Designing a Feedback-Driven Decision Support System for Dyna...\n",
      "      Authors: Timothy Oluwapelumi Adeyemi, Nadiah Fahad AlOtaibi\n",
      "      Categories: cs.AI, cs.CY\n",
      "      Published: 2025-08-09T21:24:54Z\n",
      "\n",
      "   3. [2508.07102v1] Towards High-Order Mean Flow Generative Models: Feasibility,...\n",
      "      Authors: Yang Cao, Yubin Chen...\n",
      "      Categories: cs.LG, cs.AI, cs.CV\n",
      "      Published: 2025-08-09T21:10:58Z\n",
      "\n",
      "   4. [2508.07101v1] Less Is More: Training-Free Sparse Attention with Global Loc...\n",
      "      Authors: Lijie Yang, Zhihao Zhang...\n",
      "      Categories: cs.CL, cs.AI\n",
      "      Published: 2025-08-09T21:10:33Z\n",
      "\n",
      "   5. [2508.07095v1] Hide or Highlight: Understanding the Impact of Factuality Ex...\n",
      "      Authors: Hyo Jin Do, Werner Geyer\n",
      "      Categories: cs.HC, cs.AI\n",
      "      Published: 2025-08-09T20:45:21Z\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test Date Filtering\n",
    "async def test_date_filtering():\n",
    "    \"\"\"Test date range filtering functionality.\"\"\"\n",
    "    \n",
    "    print(\"Test 2: Date Range Filtering\")\n",
    "    \n",
    "    # Use specific dates: \n",
    "    from_date = \"20250808\"  \n",
    "    to_date = \"20250809\"    \n",
    "    try:\n",
    "        date_papers = await arxiv_client.fetch_papers(\n",
    "            max_results=5,\n",
    "            from_date=from_date,\n",
    "            to_date=to_date\n",
    "        )\n",
    "        \n",
    "        print(f\"✓ Date filtering test: {len(date_papers)} papers from {from_date}-{to_date}\")\n",
    "        \n",
    "        if date_papers:\n",
    "            for i, paper in enumerate(date_papers, 1):\n",
    "                print(f\"   {i}. [{paper.arxiv_id}] {paper.title[:60]}...\")\n",
    "                print(f\"      Authors: {', '.join(paper.authors[:2])}{'...' if len(paper.authors) > 2 else ''}\")\n",
    "                print(f\"      Categories: {', '.join(paper.categories)}\")\n",
    "                print(f\"      Published: {paper.published_date}\")\n",
    "                print()\n",
    "        \n",
    "        return date_papers\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"✗ Date filtering error: {e}\")\n",
    "        return []\n",
    "\n",
    "# Run date filtering test\n",
    "date_papers = await test_date_filtering()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65dc7ac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 3: PDF Download & Caching\n",
      "Testing PDF download for: 2508.07111v1\n",
      "Title: Investigating Intersectional Bias in Large Language Models u...\n",
      "✓ PDF downloaded: 2508.07111v1.pdf (6.81 MB)\n"
     ]
    }
   ],
   "source": [
    "# Test PDF Download\n",
    "async def test_pdf_download(test_papers):\n",
    "    \"\"\"Test PDF downloading with caching.\"\"\"\n",
    "\n",
    "    print(\"Test 3: PDF Download & Caching\")\n",
    "    \n",
    "    if not test_papers:\n",
    "        print(\"No papers available for PDF download test\")\n",
    "        return None\n",
    "    \n",
    "    # Test with first paper\n",
    "    test_paper = test_papers[0]\n",
    "    print(f\"Testing PDF download for: {test_paper.arxiv_id}\")\n",
    "    print(f\"Title: {test_paper.title[:60]}...\")\n",
    "    \n",
    "    try:\n",
    "        # Download PDF \n",
    "        pdf_path = await arxiv_client.download_pdf(test_paper)\n",
    "        \n",
    "        if pdf_path and pdf_path.exists():\n",
    "            size_mb = pdf_path.stat().st_size / (1024 * 1024)\n",
    "            print(f\"✓ PDF downloaded: {pdf_path.name} ({size_mb:.2f} MB)\")\n",
    "            \n",
    "            return pdf_path\n",
    "        else:\n",
    "            print(\"✗ PDF download failed\")\n",
    "            return None\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"✗ PDF download error: {e}\")\n",
    "        return None\n",
    "\n",
    "# Run PDF download test \n",
    "pdf_path = await test_pdf_download(date_papers[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5427768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 4: PDF Parsing with Docling\n",
      "========================================\n",
      "PDF parser service created\n",
      "Config: 30 pages, 20MB\n",
      "\n",
      "Found 4 PDF files to test parsing\n",
      "Testing PDF parsing with: 2508.07111v1.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stage layout failed for run 1: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`\n",
      "Traceback (most recent call last):\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/pipeline/standard_pdf_pipeline.py\", line 289, in _process_batch\n",
      "    processed_pages = list(self.model(good[0].conv_res, pages))  # type: ignore[arg-type]\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/models/base_layout_model.py\", line 35, in __call__\n",
      "    predictions = self.predict_layout(conv_res, pages)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/models/stages/layout/layout_model.py\", line 180, in predict_layout\n",
      "    batch_predictions = self.layout_predictor.predict_batch(  # type: ignore[attr-defined]\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/utils/_contextlib.py\", line 124, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling_ibm_models/layoutmodel/layout_predictor.py\", line 222, in predict_batch\n",
      "    outputs = self._model(**inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1920, in forward\n",
      "    outputs = self.model(\n",
      "              ^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1544, in forward\n",
      "    encoder_outputs = self.encoder(\n",
      "                      ^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1191, in forward\n",
      "    layer_outputs = self.encoder[i](\n",
      "                    ^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1036, in forward\n",
      "    hidden_states = layer(\n",
      "                    ^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 939, in forward\n",
      "    hidden_states, attn_weights = self.self_attn(\n",
      "                                  ^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 289, in forward\n",
      "    attn_weights = torch.bmm(query_states, key_states.transpose(1, 2))\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`\n",
      "Stage layout failed for run 1: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`\n",
      "Traceback (most recent call last):\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/pipeline/standard_pdf_pipeline.py\", line 289, in _process_batch\n",
      "    processed_pages = list(self.model(good[0].conv_res, pages))  # type: ignore[arg-type]\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/models/base_layout_model.py\", line 35, in __call__\n",
      "    predictions = self.predict_layout(conv_res, pages)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/models/stages/layout/layout_model.py\", line 180, in predict_layout\n",
      "    batch_predictions = self.layout_predictor.predict_batch(  # type: ignore[attr-defined]\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/utils/_contextlib.py\", line 124, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling_ibm_models/layoutmodel/layout_predictor.py\", line 222, in predict_batch\n",
      "    outputs = self._model(**inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1920, in forward\n",
      "    outputs = self.model(\n",
      "              ^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1544, in forward\n",
      "    encoder_outputs = self.encoder(\n",
      "                      ^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1191, in forward\n",
      "    layer_outputs = self.encoder[i](\n",
      "                    ^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1036, in forward\n",
      "    hidden_states = layer(\n",
      "                    ^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 939, in forward\n",
      "    hidden_states, attn_weights = self.self_attn(\n",
      "                                  ^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 289, in forward\n",
      "    attn_weights = torch.bmm(query_states, key_states.transpose(1, 2))\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`\n",
      "Stage layout failed for run 1: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`\n",
      "Traceback (most recent call last):\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/pipeline/standard_pdf_pipeline.py\", line 289, in _process_batch\n",
      "    processed_pages = list(self.model(good[0].conv_res, pages))  # type: ignore[arg-type]\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/models/base_layout_model.py\", line 35, in __call__\n",
      "    predictions = self.predict_layout(conv_res, pages)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/models/stages/layout/layout_model.py\", line 180, in predict_layout\n",
      "    batch_predictions = self.layout_predictor.predict_batch(  # type: ignore[attr-defined]\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/utils/_contextlib.py\", line 124, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling_ibm_models/layoutmodel/layout_predictor.py\", line 222, in predict_batch\n",
      "    outputs = self._model(**inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1920, in forward\n",
      "    outputs = self.model(\n",
      "              ^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1544, in forward\n",
      "    encoder_outputs = self.encoder(\n",
      "                      ^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1191, in forward\n",
      "    layer_outputs = self.encoder[i](\n",
      "                    ^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1036, in forward\n",
      "    hidden_states = layer(\n",
      "                    ^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 939, in forward\n",
      "    hidden_states, attn_weights = self.self_attn(\n",
      "                                  ^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 289, in forward\n",
      "    attn_weights = torch.bmm(query_states, key_states.transpose(1, 2))\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`\n",
      "Stage layout failed for run 1: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`\n",
      "Traceback (most recent call last):\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/pipeline/standard_pdf_pipeline.py\", line 289, in _process_batch\n",
      "    processed_pages = list(self.model(good[0].conv_res, pages))  # type: ignore[arg-type]\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/models/base_layout_model.py\", line 35, in __call__\n",
      "    predictions = self.predict_layout(conv_res, pages)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/models/stages/layout/layout_model.py\", line 180, in predict_layout\n",
      "    batch_predictions = self.layout_predictor.predict_batch(  # type: ignore[attr-defined]\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/utils/_contextlib.py\", line 124, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling_ibm_models/layoutmodel/layout_predictor.py\", line 222, in predict_batch\n",
      "    outputs = self._model(**inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1920, in forward\n",
      "    outputs = self.model(\n",
      "              ^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1544, in forward\n",
      "    encoder_outputs = self.encoder(\n",
      "                      ^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1191, in forward\n",
      "    layer_outputs = self.encoder[i](\n",
      "                    ^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1036, in forward\n",
      "    hidden_states = layer(\n",
      "                    ^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 939, in forward\n",
      "    hidden_states, attn_weights = self.self_attn(\n",
      "                                  ^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 289, in forward\n",
      "    attn_weights = torch.bmm(query_states, key_states.transpose(1, 2))\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`\n",
      "Stage layout failed for run 1: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`\n",
      "Traceback (most recent call last):\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/pipeline/standard_pdf_pipeline.py\", line 289, in _process_batch\n",
      "    processed_pages = list(self.model(good[0].conv_res, pages))  # type: ignore[arg-type]\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/models/base_layout_model.py\", line 35, in __call__\n",
      "    predictions = self.predict_layout(conv_res, pages)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/models/stages/layout/layout_model.py\", line 180, in predict_layout\n",
      "    batch_predictions = self.layout_predictor.predict_batch(  # type: ignore[attr-defined]\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/utils/_contextlib.py\", line 124, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling_ibm_models/layoutmodel/layout_predictor.py\", line 222, in predict_batch\n",
      "    outputs = self._model(**inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1920, in forward\n",
      "    outputs = self.model(\n",
      "              ^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1544, in forward\n",
      "    encoder_outputs = self.encoder(\n",
      "                      ^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1191, in forward\n",
      "    layer_outputs = self.encoder[i](\n",
      "                    ^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1036, in forward\n",
      "    hidden_states = layer(\n",
      "                    ^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 939, in forward\n",
      "    hidden_states, attn_weights = self.self_attn(\n",
      "                                  ^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 289, in forward\n",
      "    attn_weights = torch.bmm(query_states, key_states.transpose(1, 2))\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`\n",
      "Stage layout failed for run 1: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`\n",
      "Traceback (most recent call last):\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/pipeline/standard_pdf_pipeline.py\", line 289, in _process_batch\n",
      "    processed_pages = list(self.model(good[0].conv_res, pages))  # type: ignore[arg-type]\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/models/base_layout_model.py\", line 35, in __call__\n",
      "    predictions = self.predict_layout(conv_res, pages)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/models/stages/layout/layout_model.py\", line 180, in predict_layout\n",
      "    batch_predictions = self.layout_predictor.predict_batch(  # type: ignore[attr-defined]\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/utils/_contextlib.py\", line 124, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling_ibm_models/layoutmodel/layout_predictor.py\", line 222, in predict_batch\n",
      "    outputs = self._model(**inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1920, in forward\n",
      "    outputs = self.model(\n",
      "              ^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1544, in forward\n",
      "    encoder_outputs = self.encoder(\n",
      "                      ^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1191, in forward\n",
      "    layer_outputs = self.encoder[i](\n",
      "                    ^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1036, in forward\n",
      "    hidden_states = layer(\n",
      "                    ^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 939, in forward\n",
      "    hidden_states, attn_weights = self.self_attn(\n",
      "                                  ^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 289, in forward\n",
      "    attn_weights = torch.bmm(query_states, key_states.transpose(1, 2))\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`\n",
      "Stage layout failed for run 1: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`\n",
      "Traceback (most recent call last):\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/pipeline/standard_pdf_pipeline.py\", line 289, in _process_batch\n",
      "    processed_pages = list(self.model(good[0].conv_res, pages))  # type: ignore[arg-type]\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/models/base_layout_model.py\", line 35, in __call__\n",
      "    predictions = self.predict_layout(conv_res, pages)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/models/stages/layout/layout_model.py\", line 180, in predict_layout\n",
      "    batch_predictions = self.layout_predictor.predict_batch(  # type: ignore[attr-defined]\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/utils/_contextlib.py\", line 124, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling_ibm_models/layoutmodel/layout_predictor.py\", line 222, in predict_batch\n",
      "    outputs = self._model(**inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1920, in forward\n",
      "    outputs = self.model(\n",
      "              ^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1544, in forward\n",
      "    encoder_outputs = self.encoder(\n",
      "                      ^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1191, in forward\n",
      "    layer_outputs = self.encoder[i](\n",
      "                    ^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1036, in forward\n",
      "    hidden_states = layer(\n",
      "                    ^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 939, in forward\n",
      "    hidden_states, attn_weights = self.self_attn(\n",
      "                                  ^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 289, in forward\n",
      "    attn_weights = torch.bmm(query_states, key_states.transpose(1, 2))\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`\n",
      "Failed to parse PDF with Docling: Conversion failed for: 2508.07111v1.pdf with status: ConversionStatus.FAILURE. Errors: Page 1: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 2: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 3: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 4: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 5: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 6: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 7: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 8: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 9: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 10: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 11: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 12: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 13: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 14: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 15: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 16: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 17: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 18: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 19: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 20: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 21: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 22: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 23: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 24: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 25: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`\n",
      "PDF path: data/arxiv_pdfs/2508.07111v1.pdf\n",
      "PDF size: 7144133 bytes\n",
      "Error type: ConversionError\n",
      "PDF processing issue likely related to page limits (current limit: 30 pages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✗ PDF parsing error: PDF processing failed, possibly due to page limit (30 pages). Error: Conversion failed for: 2508.07111v1.pdf with status: ConversionStatus.FAILURE. Errors: Page 1: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 2: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 3: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 4: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 5: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 6: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 7: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 8: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 9: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 10: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 11: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 12: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 13: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 14: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 15: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 16: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 17: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 18: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 19: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 20: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 21: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 22: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 23: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 24: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 25: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`\n",
      "This demonstrates the error handling in action\n"
     ]
    }
   ],
   "source": [
    "# Test PDF Parsing with Docling\n",
    "from src.services.pdf_parser.factory import make_pdf_parser_service\n",
    "from src.config import get_settings\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"Test 4: PDF Parsing with Docling\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Create PDF parser\n",
    "pdf_parser = make_pdf_parser_service()\n",
    "settings = get_settings()\n",
    "print(\"PDF parser service created\")\n",
    "print(f\"Config: {settings.pdf_parser.max_pages} pages, {settings.pdf_parser.max_file_size_mb}MB\")\n",
    "\n",
    "# Test parsing with actual PDF files\n",
    "cache_dir = Path(\"data/arxiv_pdfs\")\n",
    "if cache_dir.exists():\n",
    "    pdf_files = list(cache_dir.glob(\"*.pdf\"))\n",
    "    print(f\"\\nFound {len(pdf_files)} PDF files to test parsing\")\n",
    "    \n",
    "    if pdf_files:\n",
    "        # Test parsing the first PDF\n",
    "        test_pdf = pdf_files[0]\n",
    "        print(f\"Testing PDF parsing with: {test_pdf.name}\")\n",
    "        \n",
    "        try:\n",
    "            pdf_content = await pdf_parser.parse_pdf(test_pdf)\n",
    "            \n",
    "            if pdf_content:\n",
    "                print(f\"✓ PDF parsing successful!\")\n",
    "                print(f\"  Sections: {len(pdf_content.sections)}\")\n",
    "                print(f\"  Raw text length: {len(pdf_content.raw_text)} characters\")\n",
    "                print(f\"  Parser used: {pdf_content.parser_used}\")\n",
    "                \n",
    "                # Show first section as example\n",
    "                if pdf_content.sections:\n",
    "                    first_section = pdf_content.sections[0]\n",
    "                    print(f\"  First section: '{first_section.title}' ({len(first_section.content)} chars)\")\n",
    "            else:\n",
    "                print(\"✗ PDF parsing failed (Docling compatibility issue)\")\n",
    "                print(\"This is expected - not all PDFs work with Docling\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"✗ PDF parsing error: {e}\")\n",
    "            print(\"This demonstrates the error handling in action\")\n",
    "    else:\n",
    "        print(\"No PDF files available for parsing test\")\n",
    "else:\n",
    "    print(\"No PDF cache directory found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f149b12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 5: Database Storage\n",
      "========================================\n",
      "✓ Database connection created\n",
      "Storing paper: 2602.06043v1\n",
      "✓ Paper stored with ID: 2b21330f-2d5c-4c94-a3b9-4191a995894d\n",
      "   Database ID: 2b21330f-2d5c-4c94-a3b9-4191a995894d\n",
      "   arXiv ID: 2602.06043v1\n",
      "   Title: Shared LoRA Subspaces for almost Strict Continual ...\n",
      "   Authors: 5 authors\n",
      "   Categories: cs.LG, cs.AI, cs.CV\n",
      "✓ Paper retrieval test passed\n"
     ]
    }
   ],
   "source": [
    "# Test Database Storage\n",
    "from src.db.factory import make_database\n",
    "from src.repositories.paper import PaperRepository\n",
    "from src.schemas.arxiv.paper import PaperCreate\n",
    "from dateutil import parser as date_parser\n",
    "\n",
    "print(\"Test 5: Database Storage\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Create database connection\n",
    "database = make_database()\n",
    "print(\"✓ Database connection created\")\n",
    "\n",
    "if papers:\n",
    "    test_paper = papers[0]\n",
    "    print(f\"Storing paper: {test_paper.arxiv_id}\")\n",
    "    \n",
    "    try:\n",
    "        with database.get_session() as session:\n",
    "            paper_repo = PaperRepository(session)\n",
    "            \n",
    "            # Convert to database format\n",
    "            published_date = date_parser.parse(test_paper.published_date) if isinstance(test_paper.published_date, str) else test_paper.published_date\n",
    "            \n",
    "            paper_create = PaperCreate(\n",
    "                arxiv_id=test_paper.arxiv_id,\n",
    "                title=test_paper.title,\n",
    "                authors=test_paper.authors,\n",
    "                abstract=test_paper.abstract,\n",
    "                categories=test_paper.categories,\n",
    "                published_date=published_date,\n",
    "                pdf_url=test_paper.pdf_url\n",
    "            )\n",
    "            \n",
    "            # Store paper (upsert to avoid duplicates)\n",
    "            stored_paper = paper_repo.upsert(paper_create)\n",
    "            \n",
    "            if stored_paper:\n",
    "                print(f\"✓ Paper stored with ID: {stored_paper.id}\")\n",
    "                print(f\"   Database ID: {stored_paper.id}\")\n",
    "                print(f\"   arXiv ID: {stored_paper.arxiv_id}\")\n",
    "                print(f\"   Title: {stored_paper.title[:50]}...\")\n",
    "                print(f\"   Authors: {len(stored_paper.authors)} authors\")\n",
    "                print(f\"   Categories: {', '.join(stored_paper.categories)}\")\n",
    "                \n",
    "                # Test retrieval\n",
    "                retrieved_paper = paper_repo.get_by_arxiv_id(test_paper.arxiv_id)\n",
    "                if retrieved_paper:\n",
    "                    print(f\"✓ Paper retrieval test passed\")\n",
    "                else:\n",
    "                    print(f\"✗ Paper retrieval failed\")\n",
    "            else:\n",
    "                print(\"✗ Paper storage failed\")\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"✗ Database error: {e}\")\n",
    "else:\n",
    "    print(\"No papers available for database storage test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "39184b33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 6: Complete Metadata Fetcher Pipeline\n",
      "==================================================\n",
      "✓ Metadata fetcher service created\n",
      "Running small batch test (2 papers, no PDF processing for speed)...\n",
      "\n",
      "PIPELINE RESULTS:\n",
      "   Papers fetched: 2\n",
      "   PDFs downloaded: 0\n",
      "   PDFs parsed: 0\n",
      "   Papers stored: 2\n",
      "   Processing time: 0.2s\n",
      "   Errors: 0\n",
      "\n",
      "✓ Pipeline test successful!\n"
     ]
    }
   ],
   "source": [
    "# Test Complete Pipeline\n",
    "from src.services.metadata_fetcher import make_metadata_fetcher\n",
    "\n",
    "print(\"Test 6: Complete Metadata Fetcher Pipeline\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Create metadata fetcher\n",
    "metadata_fetcher = make_metadata_fetcher(arxiv_client, pdf_parser)\n",
    "print(\"✓ Metadata fetcher service created\")\n",
    "\n",
    "# Test with small batch\n",
    "print(\"Running small batch test (2 papers, no PDF processing for speed)...\")\n",
    "\n",
    "try:\n",
    "    with database.get_session() as session:\n",
    "        results = await metadata_fetcher.fetch_and_process_papers(\n",
    "            max_results=2,  \n",
    "            process_pdfs=False,  \n",
    "            store_to_db=True,\n",
    "            db_session=session\n",
    "        )\n",
    "    \n",
    "    print(\"\\nPIPELINE RESULTS:\")\n",
    "    print(f\"   Papers fetched: {results.get('papers_fetched', 0)}\")\n",
    "    print(f\"   PDFs downloaded: {results.get('pdfs_downloaded', 0)}\")\n",
    "    print(f\"   PDFs parsed: {results.get('pdfs_parsed', 0)}\")\n",
    "    print(f\"   Papers stored: {results.get('papers_stored', 0)}\")\n",
    "    print(f\"   Processing time: {results.get('processing_time', 0):.1f}s\")\n",
    "    print(f\"   Errors: {len(results.get('errors', []))}\")\n",
    "    \n",
    "    if results.get('errors'):\n",
    "        print(\"\\nErrors encountered:\")\n",
    "        for error in results.get('errors', [])[:3]:  # Show first 3 errors\n",
    "            print(f\"   - {error}\")\n",
    "    \n",
    "    if results.get('papers_fetched', 0) > 0:\n",
    "        print(\"\\n✓ Pipeline test successful!\")\n",
    "    else:\n",
    "        print(\"\\nNo papers fetched - may be arXiv API unavailability\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"✗ Pipeline error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "adad17ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 7: Airflow DAG Status\n",
      "========================================\n",
      "  Airflow UI Access:\n",
      "   URL: http://localhost:8080\n",
      "   Username: admin\n",
      "   Password: admin\n",
      "\n",
      "Available DAGs:\n",
      "   - arxiv_paper_ingestion: Paused\n",
      "   - hello_world_week1: Paused\n",
      "\n",
      "✓ No DAG import errors found\n",
      "\n",
      "  To view DAGs graphically:\n",
      "   1. Open http://localhost:8080 in your browser\n",
      "   2. Login with admin/admin\n",
      "   3. Click on 'arxiv_paper_ingestion' DAG to see the workflow\n"
     ]
    }
   ],
   "source": [
    "# Test Airflow DAGs\n",
    "print(\"Test 7: Airflow DAG Status\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "print(\"  Airflow UI Access:\")\n",
    "print(\"   URL: http://localhost:8080\")\n",
    "print(\"   Username: admin\")\n",
    "print(\"   Password: admin\")\n",
    "print()\n",
    "\n",
    "# Check DAG status using docker exec\n",
    "try:\n",
    "    result = subprocess.run(\n",
    "        [\"docker\", \"exec\", \"rag-airflow\", \"airflow\", \"dags\", \"list\"],\n",
    "        capture_output=True,\n",
    "        text=True,\n",
    "        timeout=10\n",
    "    )\n",
    "    \n",
    "    if result.returncode == 0:\n",
    "        lines = result.stdout.strip().split('\\n')\n",
    "        dag_lines = [line for line in lines if 'arxiv' in line.lower() or 'hello' in line.lower()]\n",
    "        \n",
    "        print(\"Available DAGs:\")\n",
    "        for line in dag_lines:\n",
    "            if '|' in line:\n",
    "                parts = [part.strip() for part in line.split('|')]\n",
    "                if len(parts) >= 3:\n",
    "                    dag_id = parts[0]\n",
    "                    is_paused = parts[2]\n",
    "                    status = \"Active\" if is_paused == \"False\" else \"Paused\"\n",
    "                    print(f\"   - {dag_id}: {status}\")\n",
    "        \n",
    "        # Check for import errors\n",
    "        error_result = subprocess.run(\n",
    "            [\"docker\", \"exec\", \"rag-airflow\", \"airflow\", \"dags\", \"list-import-errors\"],\n",
    "            capture_output=True,\n",
    "            text=True,\n",
    "            timeout=10\n",
    "        )\n",
    "        \n",
    "        if \"docling\" in error_result.stderr:\n",
    "            print(\"\\nKnown Issue: Docling not installed in Airflow container\")\n",
    "            print(\"   - This is expected for Week 2\")\n",
    "            print(\"   - DAG structure is complete, runtime needs container fix\")\n",
    "            print(\"   - Solution: Add docling to Airflow container startup\")\n",
    "        elif error_result.returncode == 0:\n",
    "            print(\"\\n✓ No DAG import errors found\")\n",
    "        \n",
    "    else:\n",
    "        print(f\"✗ Could not list DAGs: {result.stderr}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"✗ Airflow test error: {e}\")\n",
    "\n",
    "print(\"\\n  To view DAGs graphically:\")\n",
    "print(\"   1. Open http://localhost:8080 in your browser\")\n",
    "print(\"   2. Login with admin/admin\")\n",
    "print(\"   3. Click on 'arxiv_paper_ingestion' DAG to see the workflow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f5c4569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 8: Complete Pipeline with PDF Processing\n",
      "==================================================\n",
      "✓ Using metadata fetcher service from previous test\n",
      "Running enhanced test (3 papers with PDF processing)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stage layout failed for run 2: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`\n",
      "Traceback (most recent call last):\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/pipeline/standard_pdf_pipeline.py\", line 289, in _process_batch\n",
      "    processed_pages = list(self.model(good[0].conv_res, pages))  # type: ignore[arg-type]\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/models/base_layout_model.py\", line 35, in __call__\n",
      "    predictions = self.predict_layout(conv_res, pages)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/models/stages/layout/layout_model.py\", line 180, in predict_layout\n",
      "    batch_predictions = self.layout_predictor.predict_batch(  # type: ignore[attr-defined]\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/utils/_contextlib.py\", line 124, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling_ibm_models/layoutmodel/layout_predictor.py\", line 222, in predict_batch\n",
      "    outputs = self._model(**inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1920, in forward\n",
      "    outputs = self.model(\n",
      "              ^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1544, in forward\n",
      "    encoder_outputs = self.encoder(\n",
      "                      ^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1191, in forward\n",
      "    layer_outputs = self.encoder[i](\n",
      "                    ^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1036, in forward\n",
      "    hidden_states = layer(\n",
      "                    ^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 939, in forward\n",
      "    hidden_states, attn_weights = self.self_attn(\n",
      "                                  ^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 289, in forward\n",
      "    attn_weights = torch.bmm(query_states, key_states.transpose(1, 2))\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`\n",
      "Stage layout failed for run 2: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`\n",
      "Traceback (most recent call last):\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/pipeline/standard_pdf_pipeline.py\", line 289, in _process_batch\n",
      "    processed_pages = list(self.model(good[0].conv_res, pages))  # type: ignore[arg-type]\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/models/base_layout_model.py\", line 35, in __call__\n",
      "    predictions = self.predict_layout(conv_res, pages)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/models/stages/layout/layout_model.py\", line 180, in predict_layout\n",
      "    batch_predictions = self.layout_predictor.predict_batch(  # type: ignore[attr-defined]\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/utils/_contextlib.py\", line 124, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling_ibm_models/layoutmodel/layout_predictor.py\", line 222, in predict_batch\n",
      "    outputs = self._model(**inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1920, in forward\n",
      "    outputs = self.model(\n",
      "              ^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1544, in forward\n",
      "    encoder_outputs = self.encoder(\n",
      "                      ^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1191, in forward\n",
      "    layer_outputs = self.encoder[i](\n",
      "                    ^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1036, in forward\n",
      "    hidden_states = layer(\n",
      "                    ^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 939, in forward\n",
      "    hidden_states, attn_weights = self.self_attn(\n",
      "                                  ^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 289, in forward\n",
      "    attn_weights = torch.bmm(query_states, key_states.transpose(1, 2))\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`\n",
      "Stage layout failed for run 2: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`\n",
      "Traceback (most recent call last):\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/pipeline/standard_pdf_pipeline.py\", line 289, in _process_batch\n",
      "    processed_pages = list(self.model(good[0].conv_res, pages))  # type: ignore[arg-type]\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/models/base_layout_model.py\", line 35, in __call__\n",
      "    predictions = self.predict_layout(conv_res, pages)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/models/stages/layout/layout_model.py\", line 180, in predict_layout\n",
      "    batch_predictions = self.layout_predictor.predict_batch(  # type: ignore[attr-defined]\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/utils/_contextlib.py\", line 124, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling_ibm_models/layoutmodel/layout_predictor.py\", line 222, in predict_batch\n",
      "    outputs = self._model(**inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1920, in forward\n",
      "    outputs = self.model(\n",
      "              ^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1544, in forward\n",
      "    encoder_outputs = self.encoder(\n",
      "                      ^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1191, in forward\n",
      "    layer_outputs = self.encoder[i](\n",
      "                    ^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1036, in forward\n",
      "    hidden_states = layer(\n",
      "                    ^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 939, in forward\n",
      "    hidden_states, attn_weights = self.self_attn(\n",
      "                                  ^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 289, in forward\n",
      "    attn_weights = torch.bmm(query_states, key_states.transpose(1, 2))\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`\n",
      "Stage layout failed for run 2: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`\n",
      "Traceback (most recent call last):\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/pipeline/standard_pdf_pipeline.py\", line 289, in _process_batch\n",
      "    processed_pages = list(self.model(good[0].conv_res, pages))  # type: ignore[arg-type]\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/models/base_layout_model.py\", line 35, in __call__\n",
      "    predictions = self.predict_layout(conv_res, pages)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/models/stages/layout/layout_model.py\", line 180, in predict_layout\n",
      "    batch_predictions = self.layout_predictor.predict_batch(  # type: ignore[attr-defined]\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/utils/_contextlib.py\", line 124, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling_ibm_models/layoutmodel/layout_predictor.py\", line 222, in predict_batch\n",
      "    outputs = self._model(**inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1920, in forward\n",
      "    outputs = self.model(\n",
      "              ^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1544, in forward\n",
      "    encoder_outputs = self.encoder(\n",
      "                      ^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1191, in forward\n",
      "    layer_outputs = self.encoder[i](\n",
      "                    ^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1036, in forward\n",
      "    hidden_states = layer(\n",
      "                    ^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 939, in forward\n",
      "    hidden_states, attn_weights = self.self_attn(\n",
      "                                  ^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 289, in forward\n",
      "    attn_weights = torch.bmm(query_states, key_states.transpose(1, 2))\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`\n",
      "Stage layout failed for run 2: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`\n",
      "Traceback (most recent call last):\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/pipeline/standard_pdf_pipeline.py\", line 289, in _process_batch\n",
      "    processed_pages = list(self.model(good[0].conv_res, pages))  # type: ignore[arg-type]\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/models/base_layout_model.py\", line 35, in __call__\n",
      "    predictions = self.predict_layout(conv_res, pages)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/models/stages/layout/layout_model.py\", line 180, in predict_layout\n",
      "    batch_predictions = self.layout_predictor.predict_batch(  # type: ignore[attr-defined]\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/utils/_contextlib.py\", line 124, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling_ibm_models/layoutmodel/layout_predictor.py\", line 222, in predict_batch\n",
      "    outputs = self._model(**inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1920, in forward\n",
      "    outputs = self.model(\n",
      "              ^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1544, in forward\n",
      "    encoder_outputs = self.encoder(\n",
      "                      ^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1191, in forward\n",
      "    layer_outputs = self.encoder[i](\n",
      "                    ^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1036, in forward\n",
      "    hidden_states = layer(\n",
      "                    ^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 939, in forward\n",
      "    hidden_states, attn_weights = self.self_attn(\n",
      "                                  ^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 289, in forward\n",
      "    attn_weights = torch.bmm(query_states, key_states.transpose(1, 2))\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`\n",
      "Stage layout failed for run 2: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`\n",
      "Traceback (most recent call last):\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/pipeline/standard_pdf_pipeline.py\", line 289, in _process_batch\n",
      "    processed_pages = list(self.model(good[0].conv_res, pages))  # type: ignore[arg-type]\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/models/base_layout_model.py\", line 35, in __call__\n",
      "    predictions = self.predict_layout(conv_res, pages)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/models/stages/layout/layout_model.py\", line 180, in predict_layout\n",
      "    batch_predictions = self.layout_predictor.predict_batch(  # type: ignore[attr-defined]\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/utils/_contextlib.py\", line 124, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling_ibm_models/layoutmodel/layout_predictor.py\", line 222, in predict_batch\n",
      "    outputs = self._model(**inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1920, in forward\n",
      "    outputs = self.model(\n",
      "              ^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1544, in forward\n",
      "    encoder_outputs = self.encoder(\n",
      "                      ^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1191, in forward\n",
      "    layer_outputs = self.encoder[i](\n",
      "                    ^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1036, in forward\n",
      "    hidden_states = layer(\n",
      "                    ^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 939, in forward\n",
      "    hidden_states, attn_weights = self.self_attn(\n",
      "                                  ^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 289, in forward\n",
      "    attn_weights = torch.bmm(query_states, key_states.transpose(1, 2))\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`\n",
      "Stage layout failed for run 2: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`\n",
      "Traceback (most recent call last):\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/pipeline/standard_pdf_pipeline.py\", line 289, in _process_batch\n",
      "    processed_pages = list(self.model(good[0].conv_res, pages))  # type: ignore[arg-type]\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/models/base_layout_model.py\", line 35, in __call__\n",
      "    predictions = self.predict_layout(conv_res, pages)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/models/stages/layout/layout_model.py\", line 180, in predict_layout\n",
      "    batch_predictions = self.layout_predictor.predict_batch(  # type: ignore[attr-defined]\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/utils/_contextlib.py\", line 124, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling_ibm_models/layoutmodel/layout_predictor.py\", line 222, in predict_batch\n",
      "    outputs = self._model(**inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1920, in forward\n",
      "    outputs = self.model(\n",
      "              ^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1544, in forward\n",
      "    encoder_outputs = self.encoder(\n",
      "                      ^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1191, in forward\n",
      "    layer_outputs = self.encoder[i](\n",
      "                    ^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1036, in forward\n",
      "    hidden_states = layer(\n",
      "                    ^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 939, in forward\n",
      "    hidden_states, attn_weights = self.self_attn(\n",
      "                                  ^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 289, in forward\n",
      "    attn_weights = torch.bmm(query_states, key_states.transpose(1, 2))\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`\n",
      "Stage layout failed for run 2: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`\n",
      "Traceback (most recent call last):\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/pipeline/standard_pdf_pipeline.py\", line 289, in _process_batch\n",
      "    processed_pages = list(self.model(good[0].conv_res, pages))  # type: ignore[arg-type]\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/models/base_layout_model.py\", line 35, in __call__\n",
      "    predictions = self.predict_layout(conv_res, pages)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/models/stages/layout/layout_model.py\", line 180, in predict_layout\n",
      "    batch_predictions = self.layout_predictor.predict_batch(  # type: ignore[attr-defined]\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/utils/_contextlib.py\", line 124, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling_ibm_models/layoutmodel/layout_predictor.py\", line 222, in predict_batch\n",
      "    outputs = self._model(**inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1920, in forward\n",
      "    outputs = self.model(\n",
      "              ^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1544, in forward\n",
      "    encoder_outputs = self.encoder(\n",
      "                      ^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1191, in forward\n",
      "    layer_outputs = self.encoder[i](\n",
      "                    ^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1036, in forward\n",
      "    hidden_states = layer(\n",
      "                    ^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 939, in forward\n",
      "    hidden_states, attn_weights = self.self_attn(\n",
      "                                  ^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 289, in forward\n",
      "    attn_weights = torch.bmm(query_states, key_states.transpose(1, 2))\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`\n",
      "Stage layout failed for run 2: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`\n",
      "Traceback (most recent call last):\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/pipeline/standard_pdf_pipeline.py\", line 289, in _process_batch\n",
      "    processed_pages = list(self.model(good[0].conv_res, pages))  # type: ignore[arg-type]\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/models/base_layout_model.py\", line 35, in __call__\n",
      "    predictions = self.predict_layout(conv_res, pages)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/models/stages/layout/layout_model.py\", line 180, in predict_layout\n",
      "    batch_predictions = self.layout_predictor.predict_batch(  # type: ignore[attr-defined]\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/utils/_contextlib.py\", line 124, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling_ibm_models/layoutmodel/layout_predictor.py\", line 222, in predict_batch\n",
      "    outputs = self._model(**inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1920, in forward\n",
      "    outputs = self.model(\n",
      "              ^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1544, in forward\n",
      "    encoder_outputs = self.encoder(\n",
      "                      ^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1191, in forward\n",
      "    layer_outputs = self.encoder[i](\n",
      "                    ^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1036, in forward\n",
      "    hidden_states = layer(\n",
      "                    ^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 939, in forward\n",
      "    hidden_states, attn_weights = self.self_attn(\n",
      "                                  ^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 289, in forward\n",
      "    attn_weights = torch.bmm(query_states, key_states.transpose(1, 2))\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`\n",
      "Stage layout failed for run 2: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`\n",
      "Traceback (most recent call last):\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/pipeline/standard_pdf_pipeline.py\", line 289, in _process_batch\n",
      "    processed_pages = list(self.model(good[0].conv_res, pages))  # type: ignore[arg-type]\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/models/base_layout_model.py\", line 35, in __call__\n",
      "    predictions = self.predict_layout(conv_res, pages)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/models/stages/layout/layout_model.py\", line 180, in predict_layout\n",
      "    batch_predictions = self.layout_predictor.predict_batch(  # type: ignore[attr-defined]\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/utils/_contextlib.py\", line 124, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling_ibm_models/layoutmodel/layout_predictor.py\", line 222, in predict_batch\n",
      "    outputs = self._model(**inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1920, in forward\n",
      "    outputs = self.model(\n",
      "              ^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1544, in forward\n",
      "    encoder_outputs = self.encoder(\n",
      "                      ^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1191, in forward\n",
      "    layer_outputs = self.encoder[i](\n",
      "                    ^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1036, in forward\n",
      "    hidden_states = layer(\n",
      "                    ^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 939, in forward\n",
      "    hidden_states, attn_weights = self.self_attn(\n",
      "                                  ^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 289, in forward\n",
      "    attn_weights = torch.bmm(query_states, key_states.transpose(1, 2))\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`\n",
      "Stage layout failed for run 2: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`\n",
      "Traceback (most recent call last):\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/pipeline/standard_pdf_pipeline.py\", line 289, in _process_batch\n",
      "    processed_pages = list(self.model(good[0].conv_res, pages))  # type: ignore[arg-type]\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/models/base_layout_model.py\", line 35, in __call__\n",
      "    predictions = self.predict_layout(conv_res, pages)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/models/stages/layout/layout_model.py\", line 180, in predict_layout\n",
      "    batch_predictions = self.layout_predictor.predict_batch(  # type: ignore[attr-defined]\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/utils/_contextlib.py\", line 124, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling_ibm_models/layoutmodel/layout_predictor.py\", line 222, in predict_batch\n",
      "    outputs = self._model(**inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1920, in forward\n",
      "    outputs = self.model(\n",
      "              ^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1544, in forward\n",
      "    encoder_outputs = self.encoder(\n",
      "                      ^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1191, in forward\n",
      "    layer_outputs = self.encoder[i](\n",
      "                    ^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1036, in forward\n",
      "    hidden_states = layer(\n",
      "                    ^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 939, in forward\n",
      "    hidden_states, attn_weights = self.self_attn(\n",
      "                                  ^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 289, in forward\n",
      "    attn_weights = torch.bmm(query_states, key_states.transpose(1, 2))\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`\n",
      "Stage layout failed for run 2: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`\n",
      "Traceback (most recent call last):\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/pipeline/standard_pdf_pipeline.py\", line 289, in _process_batch\n",
      "    processed_pages = list(self.model(good[0].conv_res, pages))  # type: ignore[arg-type]\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/models/base_layout_model.py\", line 35, in __call__\n",
      "    predictions = self.predict_layout(conv_res, pages)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/models/stages/layout/layout_model.py\", line 180, in predict_layout\n",
      "    batch_predictions = self.layout_predictor.predict_batch(  # type: ignore[attr-defined]\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/utils/_contextlib.py\", line 124, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling_ibm_models/layoutmodel/layout_predictor.py\", line 222, in predict_batch\n",
      "    outputs = self._model(**inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1920, in forward\n",
      "    outputs = self.model(\n",
      "              ^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1544, in forward\n",
      "    encoder_outputs = self.encoder(\n",
      "                      ^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1191, in forward\n",
      "    layer_outputs = self.encoder[i](\n",
      "                    ^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1036, in forward\n",
      "    hidden_states = layer(\n",
      "                    ^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 939, in forward\n",
      "    hidden_states, attn_weights = self.self_attn(\n",
      "                                  ^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 289, in forward\n",
      "    attn_weights = torch.bmm(query_states, key_states.transpose(1, 2))\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`\n",
      "Stage layout failed for run 2: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`\n",
      "Traceback (most recent call last):\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/pipeline/standard_pdf_pipeline.py\", line 289, in _process_batch\n",
      "    processed_pages = list(self.model(good[0].conv_res, pages))  # type: ignore[arg-type]\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/models/base_layout_model.py\", line 35, in __call__\n",
      "    predictions = self.predict_layout(conv_res, pages)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/models/stages/layout/layout_model.py\", line 180, in predict_layout\n",
      "    batch_predictions = self.layout_predictor.predict_batch(  # type: ignore[attr-defined]\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/utils/_contextlib.py\", line 124, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling_ibm_models/layoutmodel/layout_predictor.py\", line 222, in predict_batch\n",
      "    outputs = self._model(**inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1920, in forward\n",
      "    outputs = self.model(\n",
      "              ^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1544, in forward\n",
      "    encoder_outputs = self.encoder(\n",
      "                      ^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1191, in forward\n",
      "    layer_outputs = self.encoder[i](\n",
      "                    ^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1036, in forward\n",
      "    hidden_states = layer(\n",
      "                    ^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 939, in forward\n",
      "    hidden_states, attn_weights = self.self_attn(\n",
      "                                  ^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 289, in forward\n",
      "    attn_weights = torch.bmm(query_states, key_states.transpose(1, 2))\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`\n",
      "Failed to parse PDF with Docling: Conversion failed for: 2508.11121v1.pdf with status: ConversionStatus.FAILURE. Errors: Page 1: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 2: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 3: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 4: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 5: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 6: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 7: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 8: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 9: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 10: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 11: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 12: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 13: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 14: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`\n",
      "PDF path: data/arxiv_pdfs/2508.11121v1.pdf\n",
      "PDF size: 4977516 bytes\n",
      "Error type: ConversionError\n",
      "PDF processing issue likely related to page limits (current limit: 30 pages)\n",
      "Pipeline error for 2508.11121v1: PDF processing failed, possibly due to page limit (30 pages). Error: Conversion failed for: 2508.11121v1.pdf with status: ConversionStatus.FAILURE. Errors: Page 1: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 2: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 3: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 4: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 5: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 6: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 7: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 8: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 9: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 10: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 11: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 12: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 13: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 14: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`\n",
      "Stage layout failed for run 3: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`\n",
      "Traceback (most recent call last):\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/pipeline/standard_pdf_pipeline.py\", line 289, in _process_batch\n",
      "    processed_pages = list(self.model(good[0].conv_res, pages))  # type: ignore[arg-type]\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/models/base_layout_model.py\", line 35, in __call__\n",
      "    predictions = self.predict_layout(conv_res, pages)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/models/stages/layout/layout_model.py\", line 180, in predict_layout\n",
      "    batch_predictions = self.layout_predictor.predict_batch(  # type: ignore[attr-defined]\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/utils/_contextlib.py\", line 124, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling_ibm_models/layoutmodel/layout_predictor.py\", line 222, in predict_batch\n",
      "    outputs = self._model(**inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1920, in forward\n",
      "    outputs = self.model(\n",
      "              ^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1544, in forward\n",
      "    encoder_outputs = self.encoder(\n",
      "                      ^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1191, in forward\n",
      "    layer_outputs = self.encoder[i](\n",
      "                    ^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1036, in forward\n",
      "    hidden_states = layer(\n",
      "                    ^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 939, in forward\n",
      "    hidden_states, attn_weights = self.self_attn(\n",
      "                                  ^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 289, in forward\n",
      "    attn_weights = torch.bmm(query_states, key_states.transpose(1, 2))\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`\n",
      "Stage layout failed for run 3: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`\n",
      "Traceback (most recent call last):\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/pipeline/standard_pdf_pipeline.py\", line 289, in _process_batch\n",
      "    processed_pages = list(self.model(good[0].conv_res, pages))  # type: ignore[arg-type]\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/models/base_layout_model.py\", line 35, in __call__\n",
      "    predictions = self.predict_layout(conv_res, pages)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/models/stages/layout/layout_model.py\", line 180, in predict_layout\n",
      "    batch_predictions = self.layout_predictor.predict_batch(  # type: ignore[attr-defined]\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/utils/_contextlib.py\", line 124, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling_ibm_models/layoutmodel/layout_predictor.py\", line 222, in predict_batch\n",
      "    outputs = self._model(**inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1920, in forward\n",
      "    outputs = self.model(\n",
      "              ^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1544, in forward\n",
      "    encoder_outputs = self.encoder(\n",
      "                      ^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1191, in forward\n",
      "    layer_outputs = self.encoder[i](\n",
      "                    ^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1036, in forward\n",
      "    hidden_states = layer(\n",
      "                    ^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 939, in forward\n",
      "    hidden_states, attn_weights = self.self_attn(\n",
      "                                  ^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 289, in forward\n",
      "    attn_weights = torch.bmm(query_states, key_states.transpose(1, 2))\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`\n",
      "Stage layout failed for run 3: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`\n",
      "Traceback (most recent call last):\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/pipeline/standard_pdf_pipeline.py\", line 289, in _process_batch\n",
      "    processed_pages = list(self.model(good[0].conv_res, pages))  # type: ignore[arg-type]\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/models/base_layout_model.py\", line 35, in __call__\n",
      "    predictions = self.predict_layout(conv_res, pages)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/models/stages/layout/layout_model.py\", line 180, in predict_layout\n",
      "    batch_predictions = self.layout_predictor.predict_batch(  # type: ignore[attr-defined]\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/utils/_contextlib.py\", line 124, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling_ibm_models/layoutmodel/layout_predictor.py\", line 222, in predict_batch\n",
      "    outputs = self._model(**inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1920, in forward\n",
      "    outputs = self.model(\n",
      "              ^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1544, in forward\n",
      "    encoder_outputs = self.encoder(\n",
      "                      ^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1191, in forward\n",
      "    layer_outputs = self.encoder[i](\n",
      "                    ^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1036, in forward\n",
      "    hidden_states = layer(\n",
      "                    ^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 939, in forward\n",
      "    hidden_states, attn_weights = self.self_attn(\n",
      "                                  ^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 289, in forward\n",
      "    attn_weights = torch.bmm(query_states, key_states.transpose(1, 2))\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`\n",
      "Stage layout failed for run 3: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`\n",
      "Traceback (most recent call last):\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/pipeline/standard_pdf_pipeline.py\", line 289, in _process_batch\n",
      "    processed_pages = list(self.model(good[0].conv_res, pages))  # type: ignore[arg-type]\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/models/base_layout_model.py\", line 35, in __call__\n",
      "    predictions = self.predict_layout(conv_res, pages)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/models/stages/layout/layout_model.py\", line 180, in predict_layout\n",
      "    batch_predictions = self.layout_predictor.predict_batch(  # type: ignore[attr-defined]\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/utils/_contextlib.py\", line 124, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling_ibm_models/layoutmodel/layout_predictor.py\", line 222, in predict_batch\n",
      "    outputs = self._model(**inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1920, in forward\n",
      "    outputs = self.model(\n",
      "              ^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1544, in forward\n",
      "    encoder_outputs = self.encoder(\n",
      "                      ^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1191, in forward\n",
      "    layer_outputs = self.encoder[i](\n",
      "                    ^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1036, in forward\n",
      "    hidden_states = layer(\n",
      "                    ^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 939, in forward\n",
      "    hidden_states, attn_weights = self.self_attn(\n",
      "                                  ^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 289, in forward\n",
      "    attn_weights = torch.bmm(query_states, key_states.transpose(1, 2))\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`\n",
      "Stage layout failed for run 3: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`\n",
      "Traceback (most recent call last):\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/pipeline/standard_pdf_pipeline.py\", line 289, in _process_batch\n",
      "    processed_pages = list(self.model(good[0].conv_res, pages))  # type: ignore[arg-type]\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/models/base_layout_model.py\", line 35, in __call__\n",
      "    predictions = self.predict_layout(conv_res, pages)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/models/stages/layout/layout_model.py\", line 180, in predict_layout\n",
      "    batch_predictions = self.layout_predictor.predict_batch(  # type: ignore[attr-defined]\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/utils/_contextlib.py\", line 124, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling_ibm_models/layoutmodel/layout_predictor.py\", line 222, in predict_batch\n",
      "    outputs = self._model(**inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1920, in forward\n",
      "    outputs = self.model(\n",
      "              ^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1544, in forward\n",
      "    encoder_outputs = self.encoder(\n",
      "                      ^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1191, in forward\n",
      "    layer_outputs = self.encoder[i](\n",
      "                    ^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1036, in forward\n",
      "    hidden_states = layer(\n",
      "                    ^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 939, in forward\n",
      "    hidden_states, attn_weights = self.self_attn(\n",
      "                                  ^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 289, in forward\n",
      "    attn_weights = torch.bmm(query_states, key_states.transpose(1, 2))\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`\n",
      "Stage layout failed for run 3: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`\n",
      "Traceback (most recent call last):\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/pipeline/standard_pdf_pipeline.py\", line 289, in _process_batch\n",
      "    processed_pages = list(self.model(good[0].conv_res, pages))  # type: ignore[arg-type]\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/models/base_layout_model.py\", line 35, in __call__\n",
      "    predictions = self.predict_layout(conv_res, pages)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/models/stages/layout/layout_model.py\", line 180, in predict_layout\n",
      "    batch_predictions = self.layout_predictor.predict_batch(  # type: ignore[attr-defined]\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/utils/_contextlib.py\", line 124, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling_ibm_models/layoutmodel/layout_predictor.py\", line 222, in predict_batch\n",
      "    outputs = self._model(**inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1920, in forward\n",
      "    outputs = self.model(\n",
      "              ^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1544, in forward\n",
      "    encoder_outputs = self.encoder(\n",
      "                      ^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1191, in forward\n",
      "    layer_outputs = self.encoder[i](\n",
      "                    ^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1036, in forward\n",
      "    hidden_states = layer(\n",
      "                    ^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 939, in forward\n",
      "    hidden_states, attn_weights = self.self_attn(\n",
      "                                  ^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 289, in forward\n",
      "    attn_weights = torch.bmm(query_states, key_states.transpose(1, 2))\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`\n",
      "Stage layout failed for run 3: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`\n",
      "Traceback (most recent call last):\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/pipeline/standard_pdf_pipeline.py\", line 289, in _process_batch\n",
      "    processed_pages = list(self.model(good[0].conv_res, pages))  # type: ignore[arg-type]\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/models/base_layout_model.py\", line 35, in __call__\n",
      "    predictions = self.predict_layout(conv_res, pages)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/models/stages/layout/layout_model.py\", line 180, in predict_layout\n",
      "    batch_predictions = self.layout_predictor.predict_batch(  # type: ignore[attr-defined]\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/utils/_contextlib.py\", line 124, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling_ibm_models/layoutmodel/layout_predictor.py\", line 222, in predict_batch\n",
      "    outputs = self._model(**inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1920, in forward\n",
      "    outputs = self.model(\n",
      "              ^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1544, in forward\n",
      "    encoder_outputs = self.encoder(\n",
      "                      ^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1191, in forward\n",
      "    layer_outputs = self.encoder[i](\n",
      "                    ^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1036, in forward\n",
      "    hidden_states = layer(\n",
      "                    ^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 939, in forward\n",
      "    hidden_states, attn_weights = self.self_attn(\n",
      "                                  ^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 289, in forward\n",
      "    attn_weights = torch.bmm(query_states, key_states.transpose(1, 2))\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`\n",
      "Stage layout failed for run 3: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`\n",
      "Traceback (most recent call last):\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/pipeline/standard_pdf_pipeline.py\", line 289, in _process_batch\n",
      "    processed_pages = list(self.model(good[0].conv_res, pages))  # type: ignore[arg-type]\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/models/base_layout_model.py\", line 35, in __call__\n",
      "    predictions = self.predict_layout(conv_res, pages)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/models/stages/layout/layout_model.py\", line 180, in predict_layout\n",
      "    batch_predictions = self.layout_predictor.predict_batch(  # type: ignore[attr-defined]\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/utils/_contextlib.py\", line 124, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling_ibm_models/layoutmodel/layout_predictor.py\", line 222, in predict_batch\n",
      "    outputs = self._model(**inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1920, in forward\n",
      "    outputs = self.model(\n",
      "              ^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1544, in forward\n",
      "    encoder_outputs = self.encoder(\n",
      "                      ^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1191, in forward\n",
      "    layer_outputs = self.encoder[i](\n",
      "                    ^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1036, in forward\n",
      "    hidden_states = layer(\n",
      "                    ^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 939, in forward\n",
      "    hidden_states, attn_weights = self.self_attn(\n",
      "                                  ^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 289, in forward\n",
      "    attn_weights = torch.bmm(query_states, key_states.transpose(1, 2))\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`\n",
      "Stage layout failed for run 3: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`\n",
      "Traceback (most recent call last):\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/pipeline/standard_pdf_pipeline.py\", line 289, in _process_batch\n",
      "    processed_pages = list(self.model(good[0].conv_res, pages))  # type: ignore[arg-type]\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/models/base_layout_model.py\", line 35, in __call__\n",
      "    predictions = self.predict_layout(conv_res, pages)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/models/stages/layout/layout_model.py\", line 180, in predict_layout\n",
      "    batch_predictions = self.layout_predictor.predict_batch(  # type: ignore[attr-defined]\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/utils/_contextlib.py\", line 124, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling_ibm_models/layoutmodel/layout_predictor.py\", line 222, in predict_batch\n",
      "    outputs = self._model(**inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1920, in forward\n",
      "    outputs = self.model(\n",
      "              ^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1544, in forward\n",
      "    encoder_outputs = self.encoder(\n",
      "                      ^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1191, in forward\n",
      "    layer_outputs = self.encoder[i](\n",
      "                    ^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1036, in forward\n",
      "    hidden_states = layer(\n",
      "                    ^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 939, in forward\n",
      "    hidden_states, attn_weights = self.self_attn(\n",
      "                                  ^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 289, in forward\n",
      "    attn_weights = torch.bmm(query_states, key_states.transpose(1, 2))\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`\n",
      "Stage layout failed for run 3: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`\n",
      "Traceback (most recent call last):\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/pipeline/standard_pdf_pipeline.py\", line 289, in _process_batch\n",
      "    processed_pages = list(self.model(good[0].conv_res, pages))  # type: ignore[arg-type]\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/models/base_layout_model.py\", line 35, in __call__\n",
      "    predictions = self.predict_layout(conv_res, pages)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/models/stages/layout/layout_model.py\", line 180, in predict_layout\n",
      "    batch_predictions = self.layout_predictor.predict_batch(  # type: ignore[attr-defined]\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/utils/_contextlib.py\", line 124, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling_ibm_models/layoutmodel/layout_predictor.py\", line 222, in predict_batch\n",
      "    outputs = self._model(**inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1920, in forward\n",
      "    outputs = self.model(\n",
      "              ^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1544, in forward\n",
      "    encoder_outputs = self.encoder(\n",
      "                      ^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1191, in forward\n",
      "    layer_outputs = self.encoder[i](\n",
      "                    ^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1036, in forward\n",
      "    hidden_states = layer(\n",
      "                    ^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 939, in forward\n",
      "    hidden_states, attn_weights = self.self_attn(\n",
      "                                  ^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 289, in forward\n",
      "    attn_weights = torch.bmm(query_states, key_states.transpose(1, 2))\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`\n",
      "Stage layout failed for run 3: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`\n",
      "Traceback (most recent call last):\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/pipeline/standard_pdf_pipeline.py\", line 289, in _process_batch\n",
      "    processed_pages = list(self.model(good[0].conv_res, pages))  # type: ignore[arg-type]\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/models/base_layout_model.py\", line 35, in __call__\n",
      "    predictions = self.predict_layout(conv_res, pages)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/models/stages/layout/layout_model.py\", line 180, in predict_layout\n",
      "    batch_predictions = self.layout_predictor.predict_batch(  # type: ignore[attr-defined]\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/utils/_contextlib.py\", line 124, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling_ibm_models/layoutmodel/layout_predictor.py\", line 222, in predict_batch\n",
      "    outputs = self._model(**inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1920, in forward\n",
      "    outputs = self.model(\n",
      "              ^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1544, in forward\n",
      "    encoder_outputs = self.encoder(\n",
      "                      ^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1191, in forward\n",
      "    layer_outputs = self.encoder[i](\n",
      "                    ^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1036, in forward\n",
      "    hidden_states = layer(\n",
      "                    ^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 939, in forward\n",
      "    hidden_states, attn_weights = self.self_attn(\n",
      "                                  ^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 289, in forward\n",
      "    attn_weights = torch.bmm(query_states, key_states.transpose(1, 2))\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`\n",
      "Stage layout failed for run 3: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`\n",
      "Traceback (most recent call last):\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/pipeline/standard_pdf_pipeline.py\", line 289, in _process_batch\n",
      "    processed_pages = list(self.model(good[0].conv_res, pages))  # type: ignore[arg-type]\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/models/base_layout_model.py\", line 35, in __call__\n",
      "    predictions = self.predict_layout(conv_res, pages)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/models/stages/layout/layout_model.py\", line 180, in predict_layout\n",
      "    batch_predictions = self.layout_predictor.predict_batch(  # type: ignore[attr-defined]\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/utils/_contextlib.py\", line 124, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling_ibm_models/layoutmodel/layout_predictor.py\", line 222, in predict_batch\n",
      "    outputs = self._model(**inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1920, in forward\n",
      "    outputs = self.model(\n",
      "              ^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1544, in forward\n",
      "    encoder_outputs = self.encoder(\n",
      "                      ^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1191, in forward\n",
      "    layer_outputs = self.encoder[i](\n",
      "                    ^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1036, in forward\n",
      "    hidden_states = layer(\n",
      "                    ^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 939, in forward\n",
      "    hidden_states, attn_weights = self.self_attn(\n",
      "                                  ^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 289, in forward\n",
      "    attn_weights = torch.bmm(query_states, key_states.transpose(1, 2))\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`\n",
      "Stage layout failed for run 3: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`\n",
      "Traceback (most recent call last):\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/pipeline/standard_pdf_pipeline.py\", line 289, in _process_batch\n",
      "    processed_pages = list(self.model(good[0].conv_res, pages))  # type: ignore[arg-type]\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/models/base_layout_model.py\", line 35, in __call__\n",
      "    predictions = self.predict_layout(conv_res, pages)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/models/stages/layout/layout_model.py\", line 180, in predict_layout\n",
      "    batch_predictions = self.layout_predictor.predict_batch(  # type: ignore[attr-defined]\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/utils/_contextlib.py\", line 124, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling_ibm_models/layoutmodel/layout_predictor.py\", line 222, in predict_batch\n",
      "    outputs = self._model(**inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1920, in forward\n",
      "    outputs = self.model(\n",
      "              ^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1544, in forward\n",
      "    encoder_outputs = self.encoder(\n",
      "                      ^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1191, in forward\n",
      "    layer_outputs = self.encoder[i](\n",
      "                    ^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1036, in forward\n",
      "    hidden_states = layer(\n",
      "                    ^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 939, in forward\n",
      "    hidden_states, attn_weights = self.self_attn(\n",
      "                                  ^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 289, in forward\n",
      "    attn_weights = torch.bmm(query_states, key_states.transpose(1, 2))\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`\n",
      "Stage layout failed for run 3: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`\n",
      "Traceback (most recent call last):\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/pipeline/standard_pdf_pipeline.py\", line 289, in _process_batch\n",
      "    processed_pages = list(self.model(good[0].conv_res, pages))  # type: ignore[arg-type]\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/models/base_layout_model.py\", line 35, in __call__\n",
      "    predictions = self.predict_layout(conv_res, pages)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/models/stages/layout/layout_model.py\", line 180, in predict_layout\n",
      "    batch_predictions = self.layout_predictor.predict_batch(  # type: ignore[attr-defined]\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/utils/_contextlib.py\", line 124, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling_ibm_models/layoutmodel/layout_predictor.py\", line 222, in predict_batch\n",
      "    outputs = self._model(**inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1920, in forward\n",
      "    outputs = self.model(\n",
      "              ^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1544, in forward\n",
      "    encoder_outputs = self.encoder(\n",
      "                      ^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1191, in forward\n",
      "    layer_outputs = self.encoder[i](\n",
      "                    ^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1036, in forward\n",
      "    hidden_states = layer(\n",
      "                    ^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 939, in forward\n",
      "    hidden_states, attn_weights = self.self_attn(\n",
      "                                  ^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 289, in forward\n",
      "    attn_weights = torch.bmm(query_states, key_states.transpose(1, 2))\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`\n",
      "Stage layout failed for run 3: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`\n",
      "Traceback (most recent call last):\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/pipeline/standard_pdf_pipeline.py\", line 289, in _process_batch\n",
      "    processed_pages = list(self.model(good[0].conv_res, pages))  # type: ignore[arg-type]\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/models/base_layout_model.py\", line 35, in __call__\n",
      "    predictions = self.predict_layout(conv_res, pages)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/models/stages/layout/layout_model.py\", line 180, in predict_layout\n",
      "    batch_predictions = self.layout_predictor.predict_batch(  # type: ignore[attr-defined]\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/utils/_contextlib.py\", line 124, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling_ibm_models/layoutmodel/layout_predictor.py\", line 222, in predict_batch\n",
      "    outputs = self._model(**inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1920, in forward\n",
      "    outputs = self.model(\n",
      "              ^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1544, in forward\n",
      "    encoder_outputs = self.encoder(\n",
      "                      ^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1191, in forward\n",
      "    layer_outputs = self.encoder[i](\n",
      "                    ^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1036, in forward\n",
      "    hidden_states = layer(\n",
      "                    ^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 939, in forward\n",
      "    hidden_states, attn_weights = self.self_attn(\n",
      "                                  ^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 289, in forward\n",
      "    attn_weights = torch.bmm(query_states, key_states.transpose(1, 2))\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`\n",
      "Stage layout failed for run 3: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`\n",
      "Traceback (most recent call last):\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/pipeline/standard_pdf_pipeline.py\", line 289, in _process_batch\n",
      "    processed_pages = list(self.model(good[0].conv_res, pages))  # type: ignore[arg-type]\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/models/base_layout_model.py\", line 35, in __call__\n",
      "    predictions = self.predict_layout(conv_res, pages)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/models/stages/layout/layout_model.py\", line 180, in predict_layout\n",
      "    batch_predictions = self.layout_predictor.predict_batch(  # type: ignore[attr-defined]\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/utils/_contextlib.py\", line 124, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling_ibm_models/layoutmodel/layout_predictor.py\", line 222, in predict_batch\n",
      "    outputs = self._model(**inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1920, in forward\n",
      "    outputs = self.model(\n",
      "              ^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1544, in forward\n",
      "    encoder_outputs = self.encoder(\n",
      "                      ^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1191, in forward\n",
      "    layer_outputs = self.encoder[i](\n",
      "                    ^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1036, in forward\n",
      "    hidden_states = layer(\n",
      "                    ^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 939, in forward\n",
      "    hidden_states, attn_weights = self.self_attn(\n",
      "                                  ^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 289, in forward\n",
      "    attn_weights = torch.bmm(query_states, key_states.transpose(1, 2))\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`\n",
      "Stage layout failed for run 3: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`\n",
      "Traceback (most recent call last):\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/pipeline/standard_pdf_pipeline.py\", line 289, in _process_batch\n",
      "    processed_pages = list(self.model(good[0].conv_res, pages))  # type: ignore[arg-type]\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/models/base_layout_model.py\", line 35, in __call__\n",
      "    predictions = self.predict_layout(conv_res, pages)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/models/stages/layout/layout_model.py\", line 180, in predict_layout\n",
      "    batch_predictions = self.layout_predictor.predict_batch(  # type: ignore[attr-defined]\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/utils/_contextlib.py\", line 124, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling_ibm_models/layoutmodel/layout_predictor.py\", line 222, in predict_batch\n",
      "    outputs = self._model(**inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1920, in forward\n",
      "    outputs = self.model(\n",
      "              ^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1544, in forward\n",
      "    encoder_outputs = self.encoder(\n",
      "                      ^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1191, in forward\n",
      "    layer_outputs = self.encoder[i](\n",
      "                    ^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1036, in forward\n",
      "    hidden_states = layer(\n",
      "                    ^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 939, in forward\n",
      "    hidden_states, attn_weights = self.self_attn(\n",
      "                                  ^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 289, in forward\n",
      "    attn_weights = torch.bmm(query_states, key_states.transpose(1, 2))\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`\n",
      "Stage layout failed for run 3: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`\n",
      "Traceback (most recent call last):\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/pipeline/standard_pdf_pipeline.py\", line 289, in _process_batch\n",
      "    processed_pages = list(self.model(good[0].conv_res, pages))  # type: ignore[arg-type]\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/models/base_layout_model.py\", line 35, in __call__\n",
      "    predictions = self.predict_layout(conv_res, pages)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/models/stages/layout/layout_model.py\", line 180, in predict_layout\n",
      "    batch_predictions = self.layout_predictor.predict_batch(  # type: ignore[attr-defined]\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/utils/_contextlib.py\", line 124, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling_ibm_models/layoutmodel/layout_predictor.py\", line 222, in predict_batch\n",
      "    outputs = self._model(**inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1920, in forward\n",
      "    outputs = self.model(\n",
      "              ^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1544, in forward\n",
      "    encoder_outputs = self.encoder(\n",
      "                      ^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1191, in forward\n",
      "    layer_outputs = self.encoder[i](\n",
      "                    ^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1036, in forward\n",
      "    hidden_states = layer(\n",
      "                    ^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 939, in forward\n",
      "    hidden_states, attn_weights = self.self_attn(\n",
      "                                  ^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 289, in forward\n",
      "    attn_weights = torch.bmm(query_states, key_states.transpose(1, 2))\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`\n",
      "Stage layout failed for run 3: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`\n",
      "Traceback (most recent call last):\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/pipeline/standard_pdf_pipeline.py\", line 289, in _process_batch\n",
      "    processed_pages = list(self.model(good[0].conv_res, pages))  # type: ignore[arg-type]\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/models/base_layout_model.py\", line 35, in __call__\n",
      "    predictions = self.predict_layout(conv_res, pages)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/models/stages/layout/layout_model.py\", line 180, in predict_layout\n",
      "    batch_predictions = self.layout_predictor.predict_batch(  # type: ignore[attr-defined]\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/utils/_contextlib.py\", line 124, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling_ibm_models/layoutmodel/layout_predictor.py\", line 222, in predict_batch\n",
      "    outputs = self._model(**inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1920, in forward\n",
      "    outputs = self.model(\n",
      "              ^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1544, in forward\n",
      "    encoder_outputs = self.encoder(\n",
      "                      ^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1191, in forward\n",
      "    layer_outputs = self.encoder[i](\n",
      "                    ^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1036, in forward\n",
      "    hidden_states = layer(\n",
      "                    ^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 939, in forward\n",
      "    hidden_states, attn_weights = self.self_attn(\n",
      "                                  ^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 289, in forward\n",
      "    attn_weights = torch.bmm(query_states, key_states.transpose(1, 2))\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`\n",
      "Stage layout failed for run 3: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`\n",
      "Traceback (most recent call last):\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/pipeline/standard_pdf_pipeline.py\", line 289, in _process_batch\n",
      "    processed_pages = list(self.model(good[0].conv_res, pages))  # type: ignore[arg-type]\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/models/base_layout_model.py\", line 35, in __call__\n",
      "    predictions = self.predict_layout(conv_res, pages)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/models/stages/layout/layout_model.py\", line 180, in predict_layout\n",
      "    batch_predictions = self.layout_predictor.predict_batch(  # type: ignore[attr-defined]\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/utils/_contextlib.py\", line 124, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling_ibm_models/layoutmodel/layout_predictor.py\", line 222, in predict_batch\n",
      "    outputs = self._model(**inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1920, in forward\n",
      "    outputs = self.model(\n",
      "              ^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1544, in forward\n",
      "    encoder_outputs = self.encoder(\n",
      "                      ^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1191, in forward\n",
      "    layer_outputs = self.encoder[i](\n",
      "                    ^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1036, in forward\n",
      "    hidden_states = layer(\n",
      "                    ^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 939, in forward\n",
      "    hidden_states, attn_weights = self.self_attn(\n",
      "                                  ^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 289, in forward\n",
      "    attn_weights = torch.bmm(query_states, key_states.transpose(1, 2))\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`\n",
      "Stage layout failed for run 3: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`\n",
      "Traceback (most recent call last):\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/pipeline/standard_pdf_pipeline.py\", line 289, in _process_batch\n",
      "    processed_pages = list(self.model(good[0].conv_res, pages))  # type: ignore[arg-type]\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/models/base_layout_model.py\", line 35, in __call__\n",
      "    predictions = self.predict_layout(conv_res, pages)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/models/stages/layout/layout_model.py\", line 180, in predict_layout\n",
      "    batch_predictions = self.layout_predictor.predict_batch(  # type: ignore[attr-defined]\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/utils/_contextlib.py\", line 124, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling_ibm_models/layoutmodel/layout_predictor.py\", line 222, in predict_batch\n",
      "    outputs = self._model(**inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1920, in forward\n",
      "    outputs = self.model(\n",
      "              ^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1544, in forward\n",
      "    encoder_outputs = self.encoder(\n",
      "                      ^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1191, in forward\n",
      "    layer_outputs = self.encoder[i](\n",
      "                    ^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1036, in forward\n",
      "    hidden_states = layer(\n",
      "                    ^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 939, in forward\n",
      "    hidden_states, attn_weights = self.self_attn(\n",
      "                                  ^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 289, in forward\n",
      "    attn_weights = torch.bmm(query_states, key_states.transpose(1, 2))\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`\n",
      "Stage layout failed for run 3: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`\n",
      "Traceback (most recent call last):\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/pipeline/standard_pdf_pipeline.py\", line 289, in _process_batch\n",
      "    processed_pages = list(self.model(good[0].conv_res, pages))  # type: ignore[arg-type]\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/models/base_layout_model.py\", line 35, in __call__\n",
      "    predictions = self.predict_layout(conv_res, pages)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/models/stages/layout/layout_model.py\", line 180, in predict_layout\n",
      "    batch_predictions = self.layout_predictor.predict_batch(  # type: ignore[attr-defined]\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/utils/_contextlib.py\", line 124, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling_ibm_models/layoutmodel/layout_predictor.py\", line 222, in predict_batch\n",
      "    outputs = self._model(**inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1920, in forward\n",
      "    outputs = self.model(\n",
      "              ^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1544, in forward\n",
      "    encoder_outputs = self.encoder(\n",
      "                      ^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1191, in forward\n",
      "    layer_outputs = self.encoder[i](\n",
      "                    ^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1036, in forward\n",
      "    hidden_states = layer(\n",
      "                    ^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 939, in forward\n",
      "    hidden_states, attn_weights = self.self_attn(\n",
      "                                  ^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 289, in forward\n",
      "    attn_weights = torch.bmm(query_states, key_states.transpose(1, 2))\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`\n",
      "Stage layout failed for run 3: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`\n",
      "Traceback (most recent call last):\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/pipeline/standard_pdf_pipeline.py\", line 289, in _process_batch\n",
      "    processed_pages = list(self.model(good[0].conv_res, pages))  # type: ignore[arg-type]\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/models/base_layout_model.py\", line 35, in __call__\n",
      "    predictions = self.predict_layout(conv_res, pages)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/models/stages/layout/layout_model.py\", line 180, in predict_layout\n",
      "    batch_predictions = self.layout_predictor.predict_batch(  # type: ignore[attr-defined]\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/utils/_contextlib.py\", line 124, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling_ibm_models/layoutmodel/layout_predictor.py\", line 222, in predict_batch\n",
      "    outputs = self._model(**inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1920, in forward\n",
      "    outputs = self.model(\n",
      "              ^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1544, in forward\n",
      "    encoder_outputs = self.encoder(\n",
      "                      ^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1191, in forward\n",
      "    layer_outputs = self.encoder[i](\n",
      "                    ^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1036, in forward\n",
      "    hidden_states = layer(\n",
      "                    ^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 939, in forward\n",
      "    hidden_states, attn_weights = self.self_attn(\n",
      "                                  ^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 289, in forward\n",
      "    attn_weights = torch.bmm(query_states, key_states.transpose(1, 2))\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`\n",
      "Stage layout failed for run 3: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`\n",
      "Traceback (most recent call last):\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/pipeline/standard_pdf_pipeline.py\", line 289, in _process_batch\n",
      "    processed_pages = list(self.model(good[0].conv_res, pages))  # type: ignore[arg-type]\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/models/base_layout_model.py\", line 35, in __call__\n",
      "    predictions = self.predict_layout(conv_res, pages)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/models/stages/layout/layout_model.py\", line 180, in predict_layout\n",
      "    batch_predictions = self.layout_predictor.predict_batch(  # type: ignore[attr-defined]\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/utils/_contextlib.py\", line 124, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling_ibm_models/layoutmodel/layout_predictor.py\", line 222, in predict_batch\n",
      "    outputs = self._model(**inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1920, in forward\n",
      "    outputs = self.model(\n",
      "              ^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1544, in forward\n",
      "    encoder_outputs = self.encoder(\n",
      "                      ^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1191, in forward\n",
      "    layer_outputs = self.encoder[i](\n",
      "                    ^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1036, in forward\n",
      "    hidden_states = layer(\n",
      "                    ^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 939, in forward\n",
      "    hidden_states, attn_weights = self.self_attn(\n",
      "                                  ^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 289, in forward\n",
      "    attn_weights = torch.bmm(query_states, key_states.transpose(1, 2))\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`\n",
      "Stage layout failed for run 3: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`\n",
      "Traceback (most recent call last):\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/pipeline/standard_pdf_pipeline.py\", line 289, in _process_batch\n",
      "    processed_pages = list(self.model(good[0].conv_res, pages))  # type: ignore[arg-type]\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/models/base_layout_model.py\", line 35, in __call__\n",
      "    predictions = self.predict_layout(conv_res, pages)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/models/stages/layout/layout_model.py\", line 180, in predict_layout\n",
      "    batch_predictions = self.layout_predictor.predict_batch(  # type: ignore[attr-defined]\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/utils/_contextlib.py\", line 124, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling_ibm_models/layoutmodel/layout_predictor.py\", line 222, in predict_batch\n",
      "    outputs = self._model(**inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1920, in forward\n",
      "    outputs = self.model(\n",
      "              ^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1544, in forward\n",
      "    encoder_outputs = self.encoder(\n",
      "                      ^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1191, in forward\n",
      "    layer_outputs = self.encoder[i](\n",
      "                    ^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1036, in forward\n",
      "    hidden_states = layer(\n",
      "                    ^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 939, in forward\n",
      "    hidden_states, attn_weights = self.self_attn(\n",
      "                                  ^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 289, in forward\n",
      "    attn_weights = torch.bmm(query_states, key_states.transpose(1, 2))\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`\n",
      "Stage layout failed for run 3: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`\n",
      "Traceback (most recent call last):\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/pipeline/standard_pdf_pipeline.py\", line 289, in _process_batch\n",
      "    processed_pages = list(self.model(good[0].conv_res, pages))  # type: ignore[arg-type]\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/models/base_layout_model.py\", line 35, in __call__\n",
      "    predictions = self.predict_layout(conv_res, pages)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/models/stages/layout/layout_model.py\", line 180, in predict_layout\n",
      "    batch_predictions = self.layout_predictor.predict_batch(  # type: ignore[attr-defined]\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/utils/_contextlib.py\", line 124, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling_ibm_models/layoutmodel/layout_predictor.py\", line 222, in predict_batch\n",
      "    outputs = self._model(**inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1920, in forward\n",
      "    outputs = self.model(\n",
      "              ^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1544, in forward\n",
      "    encoder_outputs = self.encoder(\n",
      "                      ^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1191, in forward\n",
      "    layer_outputs = self.encoder[i](\n",
      "                    ^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1036, in forward\n",
      "    hidden_states = layer(\n",
      "                    ^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 939, in forward\n",
      "    hidden_states, attn_weights = self.self_attn(\n",
      "                                  ^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 289, in forward\n",
      "    attn_weights = torch.bmm(query_states, key_states.transpose(1, 2))\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`\n",
      "Stage layout failed for run 3: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`\n",
      "Traceback (most recent call last):\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/pipeline/standard_pdf_pipeline.py\", line 289, in _process_batch\n",
      "    processed_pages = list(self.model(good[0].conv_res, pages))  # type: ignore[arg-type]\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/models/base_layout_model.py\", line 35, in __call__\n",
      "    predictions = self.predict_layout(conv_res, pages)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/models/stages/layout/layout_model.py\", line 180, in predict_layout\n",
      "    batch_predictions = self.layout_predictor.predict_batch(  # type: ignore[attr-defined]\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/utils/_contextlib.py\", line 124, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling_ibm_models/layoutmodel/layout_predictor.py\", line 222, in predict_batch\n",
      "    outputs = self._model(**inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1920, in forward\n",
      "    outputs = self.model(\n",
      "              ^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1544, in forward\n",
      "    encoder_outputs = self.encoder(\n",
      "                      ^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1191, in forward\n",
      "    layer_outputs = self.encoder[i](\n",
      "                    ^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1036, in forward\n",
      "    hidden_states = layer(\n",
      "                    ^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 939, in forward\n",
      "    hidden_states, attn_weights = self.self_attn(\n",
      "                                  ^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 289, in forward\n",
      "    attn_weights = torch.bmm(query_states, key_states.transpose(1, 2))\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`\n",
      "Failed to parse PDF with Docling: Conversion failed for: 2508.11112v1.pdf with status: ConversionStatus.FAILURE. Errors: Page 1: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 2: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 3: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 4: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 5: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 6: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 7: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 8: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 9: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 10: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 11: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 12: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 13: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 14: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 15: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 16: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 17: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 18: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 19: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 20: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 21: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 22: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 23: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 24: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 25: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 26: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 27: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 28: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 29: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 30: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`\n",
      "PDF path: data/arxiv_pdfs/2508.11112v1.pdf\n",
      "PDF size: 974832 bytes\n",
      "Error type: ConversionError\n",
      "PDF processing issue likely related to page limits (current limit: 30 pages)\n",
      "Pipeline error for 2508.11112v1: PDF processing failed, possibly due to page limit (30 pages). Error: Conversion failed for: 2508.11112v1.pdf with status: ConversionStatus.FAILURE. Errors: Page 1: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 2: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 3: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 4: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 5: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 6: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 7: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 8: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 9: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 10: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 11: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 12: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 13: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 14: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 15: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 16: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 17: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 18: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 19: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 20: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 21: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 22: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 23: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 24: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 25: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 26: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 27: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 28: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 29: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 30: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`\n",
      "Stage layout failed for run 4: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`\n",
      "Traceback (most recent call last):\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/pipeline/standard_pdf_pipeline.py\", line 289, in _process_batch\n",
      "    processed_pages = list(self.model(good[0].conv_res, pages))  # type: ignore[arg-type]\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/models/base_layout_model.py\", line 35, in __call__\n",
      "    predictions = self.predict_layout(conv_res, pages)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/models/stages/layout/layout_model.py\", line 180, in predict_layout\n",
      "    batch_predictions = self.layout_predictor.predict_batch(  # type: ignore[attr-defined]\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/utils/_contextlib.py\", line 124, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling_ibm_models/layoutmodel/layout_predictor.py\", line 222, in predict_batch\n",
      "    outputs = self._model(**inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1920, in forward\n",
      "    outputs = self.model(\n",
      "              ^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1544, in forward\n",
      "    encoder_outputs = self.encoder(\n",
      "                      ^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1191, in forward\n",
      "    layer_outputs = self.encoder[i](\n",
      "                    ^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1036, in forward\n",
      "    hidden_states = layer(\n",
      "                    ^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 939, in forward\n",
      "    hidden_states, attn_weights = self.self_attn(\n",
      "                                  ^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 289, in forward\n",
      "    attn_weights = torch.bmm(query_states, key_states.transpose(1, 2))\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`\n",
      "Stage layout failed for run 4: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`\n",
      "Traceback (most recent call last):\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/pipeline/standard_pdf_pipeline.py\", line 289, in _process_batch\n",
      "    processed_pages = list(self.model(good[0].conv_res, pages))  # type: ignore[arg-type]\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/models/base_layout_model.py\", line 35, in __call__\n",
      "    predictions = self.predict_layout(conv_res, pages)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/models/stages/layout/layout_model.py\", line 180, in predict_layout\n",
      "    batch_predictions = self.layout_predictor.predict_batch(  # type: ignore[attr-defined]\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/utils/_contextlib.py\", line 124, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling_ibm_models/layoutmodel/layout_predictor.py\", line 222, in predict_batch\n",
      "    outputs = self._model(**inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1920, in forward\n",
      "    outputs = self.model(\n",
      "              ^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1544, in forward\n",
      "    encoder_outputs = self.encoder(\n",
      "                      ^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1191, in forward\n",
      "    layer_outputs = self.encoder[i](\n",
      "                    ^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1036, in forward\n",
      "    hidden_states = layer(\n",
      "                    ^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 939, in forward\n",
      "    hidden_states, attn_weights = self.self_attn(\n",
      "                                  ^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 289, in forward\n",
      "    attn_weights = torch.bmm(query_states, key_states.transpose(1, 2))\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`\n",
      "Stage layout failed for run 4: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`\n",
      "Traceback (most recent call last):\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/pipeline/standard_pdf_pipeline.py\", line 289, in _process_batch\n",
      "    processed_pages = list(self.model(good[0].conv_res, pages))  # type: ignore[arg-type]\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/models/base_layout_model.py\", line 35, in __call__\n",
      "    predictions = self.predict_layout(conv_res, pages)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/models/stages/layout/layout_model.py\", line 180, in predict_layout\n",
      "    batch_predictions = self.layout_predictor.predict_batch(  # type: ignore[attr-defined]\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/utils/_contextlib.py\", line 124, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling_ibm_models/layoutmodel/layout_predictor.py\", line 222, in predict_batch\n",
      "    outputs = self._model(**inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1920, in forward\n",
      "    outputs = self.model(\n",
      "              ^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1544, in forward\n",
      "    encoder_outputs = self.encoder(\n",
      "                      ^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1191, in forward\n",
      "    layer_outputs = self.encoder[i](\n",
      "                    ^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1036, in forward\n",
      "    hidden_states = layer(\n",
      "                    ^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 939, in forward\n",
      "    hidden_states, attn_weights = self.self_attn(\n",
      "                                  ^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 289, in forward\n",
      "    attn_weights = torch.bmm(query_states, key_states.transpose(1, 2))\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`\n",
      "Stage layout failed for run 4: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`\n",
      "Traceback (most recent call last):\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/pipeline/standard_pdf_pipeline.py\", line 289, in _process_batch\n",
      "    processed_pages = list(self.model(good[0].conv_res, pages))  # type: ignore[arg-type]\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/models/base_layout_model.py\", line 35, in __call__\n",
      "    predictions = self.predict_layout(conv_res, pages)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/models/stages/layout/layout_model.py\", line 180, in predict_layout\n",
      "    batch_predictions = self.layout_predictor.predict_batch(  # type: ignore[attr-defined]\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/utils/_contextlib.py\", line 124, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling_ibm_models/layoutmodel/layout_predictor.py\", line 222, in predict_batch\n",
      "    outputs = self._model(**inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1920, in forward\n",
      "    outputs = self.model(\n",
      "              ^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1544, in forward\n",
      "    encoder_outputs = self.encoder(\n",
      "                      ^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1191, in forward\n",
      "    layer_outputs = self.encoder[i](\n",
      "                    ^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1036, in forward\n",
      "    hidden_states = layer(\n",
      "                    ^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 939, in forward\n",
      "    hidden_states, attn_weights = self.self_attn(\n",
      "                                  ^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 289, in forward\n",
      "    attn_weights = torch.bmm(query_states, key_states.transpose(1, 2))\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`\n",
      "Stage layout failed for run 4: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`\n",
      "Traceback (most recent call last):\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/pipeline/standard_pdf_pipeline.py\", line 289, in _process_batch\n",
      "    processed_pages = list(self.model(good[0].conv_res, pages))  # type: ignore[arg-type]\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/models/base_layout_model.py\", line 35, in __call__\n",
      "    predictions = self.predict_layout(conv_res, pages)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/models/stages/layout/layout_model.py\", line 180, in predict_layout\n",
      "    batch_predictions = self.layout_predictor.predict_batch(  # type: ignore[attr-defined]\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/utils/_contextlib.py\", line 124, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling_ibm_models/layoutmodel/layout_predictor.py\", line 222, in predict_batch\n",
      "    outputs = self._model(**inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1920, in forward\n",
      "    outputs = self.model(\n",
      "              ^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1544, in forward\n",
      "    encoder_outputs = self.encoder(\n",
      "                      ^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1191, in forward\n",
      "    layer_outputs = self.encoder[i](\n",
      "                    ^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1036, in forward\n",
      "    hidden_states = layer(\n",
      "                    ^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 939, in forward\n",
      "    hidden_states, attn_weights = self.self_attn(\n",
      "                                  ^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 289, in forward\n",
      "    attn_weights = torch.bmm(query_states, key_states.transpose(1, 2))\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`\n",
      "Stage layout failed for run 4: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`\n",
      "Traceback (most recent call last):\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/pipeline/standard_pdf_pipeline.py\", line 289, in _process_batch\n",
      "    processed_pages = list(self.model(good[0].conv_res, pages))  # type: ignore[arg-type]\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/models/base_layout_model.py\", line 35, in __call__\n",
      "    predictions = self.predict_layout(conv_res, pages)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/models/stages/layout/layout_model.py\", line 180, in predict_layout\n",
      "    batch_predictions = self.layout_predictor.predict_batch(  # type: ignore[attr-defined]\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/utils/_contextlib.py\", line 124, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling_ibm_models/layoutmodel/layout_predictor.py\", line 222, in predict_batch\n",
      "    outputs = self._model(**inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1920, in forward\n",
      "    outputs = self.model(\n",
      "              ^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1544, in forward\n",
      "    encoder_outputs = self.encoder(\n",
      "                      ^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1191, in forward\n",
      "    layer_outputs = self.encoder[i](\n",
      "                    ^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1036, in forward\n",
      "    hidden_states = layer(\n",
      "                    ^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 939, in forward\n",
      "    hidden_states, attn_weights = self.self_attn(\n",
      "                                  ^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 289, in forward\n",
      "    attn_weights = torch.bmm(query_states, key_states.transpose(1, 2))\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`\n",
      "Stage layout failed for run 4: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`\n",
      "Traceback (most recent call last):\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/pipeline/standard_pdf_pipeline.py\", line 289, in _process_batch\n",
      "    processed_pages = list(self.model(good[0].conv_res, pages))  # type: ignore[arg-type]\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/models/base_layout_model.py\", line 35, in __call__\n",
      "    predictions = self.predict_layout(conv_res, pages)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/models/stages/layout/layout_model.py\", line 180, in predict_layout\n",
      "    batch_predictions = self.layout_predictor.predict_batch(  # type: ignore[attr-defined]\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/utils/_contextlib.py\", line 124, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling_ibm_models/layoutmodel/layout_predictor.py\", line 222, in predict_batch\n",
      "    outputs = self._model(**inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1920, in forward\n",
      "    outputs = self.model(\n",
      "              ^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1544, in forward\n",
      "    encoder_outputs = self.encoder(\n",
      "                      ^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1191, in forward\n",
      "    layer_outputs = self.encoder[i](\n",
      "                    ^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1036, in forward\n",
      "    hidden_states = layer(\n",
      "                    ^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 939, in forward\n",
      "    hidden_states, attn_weights = self.self_attn(\n",
      "                                  ^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 289, in forward\n",
      "    attn_weights = torch.bmm(query_states, key_states.transpose(1, 2))\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`\n",
      "Stage layout failed for run 4: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`\n",
      "Traceback (most recent call last):\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/pipeline/standard_pdf_pipeline.py\", line 289, in _process_batch\n",
      "    processed_pages = list(self.model(good[0].conv_res, pages))  # type: ignore[arg-type]\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/models/base_layout_model.py\", line 35, in __call__\n",
      "    predictions = self.predict_layout(conv_res, pages)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/models/stages/layout/layout_model.py\", line 180, in predict_layout\n",
      "    batch_predictions = self.layout_predictor.predict_batch(  # type: ignore[attr-defined]\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/utils/_contextlib.py\", line 124, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling_ibm_models/layoutmodel/layout_predictor.py\", line 222, in predict_batch\n",
      "    outputs = self._model(**inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1920, in forward\n",
      "    outputs = self.model(\n",
      "              ^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1544, in forward\n",
      "    encoder_outputs = self.encoder(\n",
      "                      ^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1191, in forward\n",
      "    layer_outputs = self.encoder[i](\n",
      "                    ^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1036, in forward\n",
      "    hidden_states = layer(\n",
      "                    ^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 939, in forward\n",
      "    hidden_states, attn_weights = self.self_attn(\n",
      "                                  ^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 289, in forward\n",
      "    attn_weights = torch.bmm(query_states, key_states.transpose(1, 2))\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`\n",
      "Stage layout failed for run 4: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`\n",
      "Traceback (most recent call last):\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/pipeline/standard_pdf_pipeline.py\", line 289, in _process_batch\n",
      "    processed_pages = list(self.model(good[0].conv_res, pages))  # type: ignore[arg-type]\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/models/base_layout_model.py\", line 35, in __call__\n",
      "    predictions = self.predict_layout(conv_res, pages)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/models/stages/layout/layout_model.py\", line 180, in predict_layout\n",
      "    batch_predictions = self.layout_predictor.predict_batch(  # type: ignore[attr-defined]\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/utils/_contextlib.py\", line 124, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling_ibm_models/layoutmodel/layout_predictor.py\", line 222, in predict_batch\n",
      "    outputs = self._model(**inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1920, in forward\n",
      "    outputs = self.model(\n",
      "              ^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1544, in forward\n",
      "    encoder_outputs = self.encoder(\n",
      "                      ^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1191, in forward\n",
      "    layer_outputs = self.encoder[i](\n",
      "                    ^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1036, in forward\n",
      "    hidden_states = layer(\n",
      "                    ^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 939, in forward\n",
      "    hidden_states, attn_weights = self.self_attn(\n",
      "                                  ^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 289, in forward\n",
      "    attn_weights = torch.bmm(query_states, key_states.transpose(1, 2))\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`\n",
      "Stage layout failed for run 4: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`\n",
      "Traceback (most recent call last):\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/pipeline/standard_pdf_pipeline.py\", line 289, in _process_batch\n",
      "    processed_pages = list(self.model(good[0].conv_res, pages))  # type: ignore[arg-type]\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/models/base_layout_model.py\", line 35, in __call__\n",
      "    predictions = self.predict_layout(conv_res, pages)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/models/stages/layout/layout_model.py\", line 180, in predict_layout\n",
      "    batch_predictions = self.layout_predictor.predict_batch(  # type: ignore[attr-defined]\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/utils/_contextlib.py\", line 124, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling_ibm_models/layoutmodel/layout_predictor.py\", line 222, in predict_batch\n",
      "    outputs = self._model(**inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1920, in forward\n",
      "    outputs = self.model(\n",
      "              ^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1544, in forward\n",
      "    encoder_outputs = self.encoder(\n",
      "                      ^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1191, in forward\n",
      "    layer_outputs = self.encoder[i](\n",
      "                    ^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1036, in forward\n",
      "    hidden_states = layer(\n",
      "                    ^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 939, in forward\n",
      "    hidden_states, attn_weights = self.self_attn(\n",
      "                                  ^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 289, in forward\n",
      "    attn_weights = torch.bmm(query_states, key_states.transpose(1, 2))\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`\n",
      "Stage layout failed for run 4: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`\n",
      "Traceback (most recent call last):\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/pipeline/standard_pdf_pipeline.py\", line 289, in _process_batch\n",
      "    processed_pages = list(self.model(good[0].conv_res, pages))  # type: ignore[arg-type]\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/models/base_layout_model.py\", line 35, in __call__\n",
      "    predictions = self.predict_layout(conv_res, pages)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/models/stages/layout/layout_model.py\", line 180, in predict_layout\n",
      "    batch_predictions = self.layout_predictor.predict_batch(  # type: ignore[attr-defined]\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/utils/_contextlib.py\", line 124, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling_ibm_models/layoutmodel/layout_predictor.py\", line 222, in predict_batch\n",
      "    outputs = self._model(**inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1920, in forward\n",
      "    outputs = self.model(\n",
      "              ^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1544, in forward\n",
      "    encoder_outputs = self.encoder(\n",
      "                      ^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1191, in forward\n",
      "    layer_outputs = self.encoder[i](\n",
      "                    ^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1036, in forward\n",
      "    hidden_states = layer(\n",
      "                    ^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 939, in forward\n",
      "    hidden_states, attn_weights = self.self_attn(\n",
      "                                  ^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 289, in forward\n",
      "    attn_weights = torch.bmm(query_states, key_states.transpose(1, 2))\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`\n",
      "Stage layout failed for run 4: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`\n",
      "Traceback (most recent call last):\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/pipeline/standard_pdf_pipeline.py\", line 289, in _process_batch\n",
      "    processed_pages = list(self.model(good[0].conv_res, pages))  # type: ignore[arg-type]\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/models/base_layout_model.py\", line 35, in __call__\n",
      "    predictions = self.predict_layout(conv_res, pages)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling/models/stages/layout/layout_model.py\", line 180, in predict_layout\n",
      "    batch_predictions = self.layout_predictor.predict_batch(  # type: ignore[attr-defined]\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/utils/_contextlib.py\", line 124, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/docling_ibm_models/layoutmodel/layout_predictor.py\", line 222, in predict_batch\n",
      "    outputs = self._model(**inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1920, in forward\n",
      "    outputs = self.model(\n",
      "              ^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1544, in forward\n",
      "    encoder_outputs = self.encoder(\n",
      "                      ^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1191, in forward\n",
      "    layer_outputs = self.encoder[i](\n",
      "                    ^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 1036, in forward\n",
      "    hidden_states = layer(\n",
      "                    ^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 939, in forward\n",
      "    hidden_states, attn_weights = self.self_attn(\n",
      "                                  ^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1776, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1787, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/media/akshay/DATA/Portfolio/RAG/.venv/lib/python3.12/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py\", line 289, in forward\n",
      "    attn_weights = torch.bmm(query_states, key_states.transpose(1, 2))\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`\n",
      "Failed to parse PDF with Docling: Conversion failed for: 2508.11110v1.pdf with status: ConversionStatus.FAILURE. Errors: Page 1: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 2: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 3: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 4: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 5: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 6: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 7: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 8: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 9: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 10: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 11: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 12: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`\n",
      "PDF path: data/arxiv_pdfs/2508.11110v1.pdf\n",
      "PDF size: 5047016 bytes\n",
      "Error type: ConversionError\n",
      "PDF processing issue likely related to page limits (current limit: 30 pages)\n",
      "Pipeline error for 2508.11110v1: PDF processing failed, possibly due to page limit (30 pages). Error: Conversion failed for: 2508.11110v1.pdf with status: ConversionStatus.FAILURE. Errors: Page 1: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 2: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 3: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 4: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 5: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 6: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 7: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 8: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 9: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 10: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 11: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 12: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`\n",
      "Pipeline error for 2508.11121v1: Pipeline error for 2508.11121v1: PDF processing failed, possibly due to page limit (30 pages). Error: Conversion failed for: 2508.11121v1.pdf with status: ConversionStatus.FAILURE. Errors: Page 1: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 2: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 3: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 4: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 5: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 6: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 7: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 8: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 9: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 10: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 11: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 12: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 13: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 14: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`\n",
      "Pipeline error for 2508.11112v1: Pipeline error for 2508.11112v1: PDF processing failed, possibly due to page limit (30 pages). Error: Conversion failed for: 2508.11112v1.pdf with status: ConversionStatus.FAILURE. Errors: Page 1: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 2: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 3: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 4: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 5: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 6: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 7: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 8: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 9: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 10: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 11: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 12: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 13: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 14: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 15: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 16: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 17: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 18: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 19: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 20: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 21: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 22: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 23: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 24: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 25: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 26: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 27: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 28: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 29: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 30: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`\n",
      "Pipeline error for 2508.11110v1: Pipeline error for 2508.11110v1: PDF processing failed, possibly due to page limit (30 pages). Error: Conversion failed for: 2508.11110v1.pdf with status: ConversionStatus.FAILURE. Errors: Page 1: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 2: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 3: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 4: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 5: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 6: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 7: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 8: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 9: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 10: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 11: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 12: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`\n",
      "Errors summary:\n",
      "  1. Pipeline error for 2508.11121v1: Pipeline error for 2508.11121v1: PDF processing failed, possibly due to page limit (30 pages). Error: Conversion failed for: 2508.11121v1.pdf with status: ConversionStatus.FAILURE. Errors: Page 1: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 2: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 3: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 4: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 5: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 6: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 7: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 8: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 9: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 10: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 11: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 12: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 13: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 14: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`\n",
      "  2. Pipeline error for 2508.11112v1: Pipeline error for 2508.11112v1: PDF processing failed, possibly due to page limit (30 pages). Error: Conversion failed for: 2508.11112v1.pdf with status: ConversionStatus.FAILURE. Errors: Page 1: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 2: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 3: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 4: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 5: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 6: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 7: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 8: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 9: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 10: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 11: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 12: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 13: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 14: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 15: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 16: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 17: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 18: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 19: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 20: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 21: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 22: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 23: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 24: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 25: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 26: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 27: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 28: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 29: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 30: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`\n",
      "  3. Pipeline error for 2508.11110v1: Pipeline error for 2508.11110v1: PDF processing failed, possibly due to page limit (30 pages). Error: Conversion failed for: 2508.11110v1.pdf with status: ConversionStatus.FAILURE. Errors: Page 1: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 2: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 3: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 4: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 5: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 6: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 7: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 8: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 9: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 10: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 11: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 12: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ENHANCED PIPELINE RESULTS:\n",
      "   Papers fetched: 3\n",
      "   PDFs downloaded: 0\n",
      "   PDFs parsed: 0\n",
      "   Papers stored: 3\n",
      "   Processing time: 9.7s\n",
      "   Errors: 3\n",
      "   Download success rate: 0.0%\n",
      "   Parse success rate: 0.0%\n",
      "\n",
      "Errors encountered (showing graceful error handling):\n",
      "   - Pipeline error for 2508.11121v1: Pipeline error for 2508.11121v1: PDF processing failed, possibly due to page limit (30 pages). Error: Conversion failed for: 2508.11121v1.pdf with status: ConversionStatus.FAILURE. Errors: Page 1: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 2: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 3: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 4: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 5: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 6: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 7: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 8: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 9: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 10: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 11: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 12: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 13: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 14: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`\n",
      "   - Pipeline error for 2508.11112v1: Pipeline error for 2508.11112v1: PDF processing failed, possibly due to page limit (30 pages). Error: Conversion failed for: 2508.11112v1.pdf with status: ConversionStatus.FAILURE. Errors: Page 1: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 2: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 3: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 4: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 5: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 6: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 7: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 8: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 9: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 10: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 11: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 12: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 13: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 14: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 15: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 16: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 17: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 18: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 19: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 20: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 21: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 22: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 23: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 24: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 25: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 26: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 27: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 28: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 29: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 30: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`\n",
      "   - Pipeline error for 2508.11110v1: Pipeline error for 2508.11110v1: PDF processing failed, possibly due to page limit (30 pages). Error: Conversion failed for: 2508.11110v1.pdf with status: ConversionStatus.FAILURE. Errors: Page 1: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 2: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 3: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 4: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 5: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 6: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 7: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 8: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 9: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 10: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 11: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`; Page 12: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`\n",
      "\n",
      "✓ Enhanced pipeline test successful!\n",
      "✓ System continued processing despite PDF failures\n"
     ]
    }
   ],
   "source": [
    "# Test Complete Pipeline with PDF Processing\n",
    "print(\"Test 8: Complete Pipeline with PDF Processing\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Reuse metadata fetcher from Test 6\n",
    "print(\"✓ Using metadata fetcher service from previous test\")\n",
    "\n",
    "# Test with small batch including PDF processing\n",
    "print(\"Running enhanced test (3 papers with PDF processing)...\")\n",
    "\n",
    "try:\n",
    "    with database.get_session() as session:\n",
    "        results = await metadata_fetcher.fetch_and_process_papers(\n",
    "            max_results=3,  # Small batch\n",
    "            from_date=\"20250813\",  # Recent date\n",
    "            to_date=\"20250814\",\n",
    "            process_pdfs=True,  \n",
    "            store_to_db=True,\n",
    "            db_session=session\n",
    "        )\n",
    "    \n",
    "    print(\"\\nENHANCED PIPELINE RESULTS:\")\n",
    "    print(f\"   Papers fetched: {results.get('papers_fetched', 0)}\")\n",
    "    print(f\"   PDFs downloaded: {results.get('pdfs_downloaded', 0)}\")\n",
    "    print(f\"   PDFs parsed: {results.get('pdfs_parsed', 0)}\")\n",
    "    print(f\"   Papers stored: {results.get('papers_stored', 0)}\")\n",
    "    print(f\"   Processing time: {results.get('processing_time', 0):.1f}s\")\n",
    "    print(f\"   Errors: {len(results.get('errors', []))}\")\n",
    "    \n",
    "    # Show success rates\n",
    "    if results.get('papers_fetched', 0) > 0:\n",
    "        download_rate = (results['pdfs_downloaded'] / results['papers_fetched']) * 100\n",
    "        parse_rate = (results['pdfs_parsed'] / results['pdfs_downloaded']) * 100 if results.get('pdfs_downloaded', 0) > 0 else 0\n",
    "        print(f\"   Download success rate: {download_rate:.1f}%\")\n",
    "        print(f\"   Parse success rate: {parse_rate:.1f}%\")\n",
    "    \n",
    "    if results.get('errors'):\n",
    "        print(\"\\nErrors encountered (showing graceful error handling):\")\n",
    "        for error in results.get('errors', [])[:3]:  # Show first 3 errors\n",
    "            print(f\"   - {error}\")\n",
    "    \n",
    "    if results.get('papers_fetched', 0) > 0:\n",
    "        print(\"\\n✓ Enhanced pipeline test successful!\")\n",
    "        if results.get('errors'):\n",
    "            print(\"✓ System continued processing despite PDF failures\")\n",
    "    else:\n",
    "        print(\"\\n! No papers fetched - may be arXiv API unavailability\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"✗ Pipeline error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549bde20-f377-449d-bed8-bd465203885f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
